{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11153574,"sourceType":"datasetVersion","datasetId":6958923},{"sourceId":11173133,"sourceType":"datasetVersion","datasetId":6945353},{"sourceId":11514066,"sourceType":"datasetVersion","datasetId":7220397}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Process UCF-Small_Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef process_large_csv(input_csv, output_csv=None, dataset_type=\"val\"):\n    \"\"\"\n    Reads a large CSV file, extracts required columns, modifies the image_path \n    by removing dataset-specific prefixes and adding the correct directory,\n    and optionally saves the processed DataFrame.\n    \n    Parameters:\n    - input_csv (str): Path to the input CSV file.\n    - output_csv (str, optional): Path to save the processed CSV file. If None, it won't save.\n    - dataset_type (str): Type of dataset ('train', 'test', 'val') to determine path adjustments.\n    \n    Returns:\n    - pd.DataFrame: Processed DataFrame with updated image paths.\n    \"\"\"\n    #use_cols = [\"image_path\", \"caption\"]  # Load only needed columns\n\n    # Read CSV with only required columns\n    df = pd.read_csv(input_csv)\n\n    # Define path mappings based on dataset type\n    path_mappings = {\n        \"train\": (\"train_output_frames/\", \"/kaggle/input/ucf-small-dataset/train_ucf_output/\"),\n        \"test\": (\"test_output_frames/\", \"/kaggle/input/ucf-small-dataset/test_ucf_output/\"),\n        \"val\": (\"val_output_frames/\", \"/kaggle/input/ucf-small-dataset/val_ucf_output/\")\n    }\n\n    # Get the correct replacement values\n    remove_prefix, new_prefix = path_mappings.get(dataset_type, (\"\", \"\"))\n\n    # Remove the dataset-specific prefix and add the correct directory\n    df[\"image_path\"] = df[\"image_path\"].str.replace(remove_prefix, \"\", regex=False)\n    df[\"image_path\"] = new_prefix + df[\"image_path\"]\n\n    # Save the processed DataFrame if an output path is provided\n    if output_csv:\n        df.to_csv(output_csv, index=False)\n\n    return df\n\n# Process train, test, and validation datasets with the correct path adjustments\nds1 = process_large_csv(\"/kaggle/input/ucf-small-dataset/train_image_captions.csv\", \n                             \"train_ucf_set.csv\", dataset_type=\"train\")\nds2 = process_large_csv(\"/kaggle/input/ucf-small-dataset/test_image_captions.csv\", \n                            \"test_ucf_set.csv\", dataset_type=\"test\")\nds3 = process_large_csv(\"/kaggle/input/ucf-small-dataset/val_image_captions.csv\", \n                             \"valid_ucf_set.csv\", dataset_type=\"val\")\n\n# train_ds  # Display first few rows\nds1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:50:17.452514Z","iopub.execute_input":"2025-03-26T17:50:17.452791Z","iopub.status.idle":"2025-03-26T17:50:17.849218Z","shell.execute_reply.started":"2025-03-26T17:50:17.452761Z","shell.execute_reply":"2025-03-26T17:50:17.848370Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                             image_path  \\\n0     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n1     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n2     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n3     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n4     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n...                                                 ...   \n1038  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n1039  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n1040  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n1041  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n1042  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n\n                                                caption  \\\n0                A police car drove into a grassy field   \n1     The police car stopped, and two police officer...   \n2     The police car stopped, and two police officer...   \n3     The police car stopped, and two police officer...   \n4     The police car stopped, and two police officer...   \n...                                                 ...   \n1038  The lights in the room turned on, someone was ...   \n1039  The room is illuminated by light, and the shel...   \n1040  The lights in the room are off, and there are ...   \n1041  The lights in the room are off, and there are ...   \n1042  The lights in the room are on, there are many ...   \n\n                  video_key category  frame_index  \n0             Abuse006_x264    Abuse          141  \n1             Abuse006_x264    Abuse          283  \n2             Abuse006_x264    Abuse          283  \n3             Abuse006_x264    Abuse          296  \n4             Abuse006_x264    Abuse          309  \n...                     ...      ...          ...  \n1038  Normal_Videos031_x264   Normal         2611  \n1039  Normal_Videos031_x264   Normal         2952  \n1040  Normal_Videos031_x264   Normal         3294  \n1041  Normal_Videos031_x264   Normal         3294  \n1042  Normal_Videos031_x264   Normal         3313  \n\n[1043 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>video_key</th>\n      <th>category</th>\n      <th>frame_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>A police car drove into a grassy field</td>\n      <td>Abuse006_x264</td>\n      <td>Abuse</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The police car stopped, and two police officer...</td>\n      <td>Abuse006_x264</td>\n      <td>Abuse</td>\n      <td>283</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The police car stopped, and two police officer...</td>\n      <td>Abuse006_x264</td>\n      <td>Abuse</td>\n      <td>283</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The police car stopped, and two police officer...</td>\n      <td>Abuse006_x264</td>\n      <td>Abuse</td>\n      <td>296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The police car stopped, and two police officer...</td>\n      <td>Abuse006_x264</td>\n      <td>Abuse</td>\n      <td>309</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1038</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The lights in the room turned on, someone was ...</td>\n      <td>Normal_Videos031_x264</td>\n      <td>Normal</td>\n      <td>2611</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The room is illuminated by light, and the shel...</td>\n      <td>Normal_Videos031_x264</td>\n      <td>Normal</td>\n      <td>2952</td>\n    </tr>\n    <tr>\n      <th>1040</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The lights in the room are off, and there are ...</td>\n      <td>Normal_Videos031_x264</td>\n      <td>Normal</td>\n      <td>3294</td>\n    </tr>\n    <tr>\n      <th>1041</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The lights in the room are off, and there are ...</td>\n      <td>Normal_Videos031_x264</td>\n      <td>Normal</td>\n      <td>3294</td>\n    </tr>\n    <tr>\n      <th>1042</th>\n      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n      <td>The lights in the room are on, there are many ...</td>\n      <td>Normal_Videos031_x264</td>\n      <td>Normal</td>\n      <td>3313</td>\n    </tr>\n  </tbody>\n</table>\n<p>1043 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the full dataset\ndf = pd.read_csv('/kaggle/input/ucf-crime-extracted-frames/test_image_captions.csv)\n\n# Initialize split containers\ntrain_list, val_list, test_list = [], [], []\n\n# Group by category\nfor category, group in df.groupby('category'):\n    # Get all unique videos in this category\n    video_keys = group['video_key'].unique()\n    \n    # Split into train (65%) and temp (35%)\n    train_videos, temp_videos = train_test_split(\n        video_keys, test_size=0.35, random_state=42\n    )\n    \n    # Split temp into val (15%) and test (20%)\n    val_videos, test_videos = train_test_split(\n        temp_videos,\n        test_size=(20 / 35),  # Adjusted for original total\n        random_state=42\n    )\n    \n    # Get dataframes for each split\n    train_list.append(group[group['video_key'].isin(train_videos)])\n    val_list.append(group[group['video_key'].isin(val_videos)])\n    test_list.append(group[group['video_key'].isin(test_videos)])\n\n# Concatenate all splits\ntrain_df = pd.concat(train_list).reset_index(drop=True)\nval_df = pd.concat(val_list).reset_index(drop=True)\ntest_df = pd.concat(test_list).reset_index(drop=True)\n\n# Save splits\ntrain_df.to_csv('train_image_captions.csv', index=False)\nval_df.to_csv('val_image_captions.csv', index=False)\ntest_df.to_csv('test_image_captions.csv', index=False)\n\nprint(f\"Train: {len(train_df)} samples\")\nprint(f\"Val: {len(val_df)} samples\")\nprint(f\"Test: {len(test_df)} samples\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Process UCF-UCA-Dataset","metadata":{}},{"cell_type":"code","source":"\n# import pandas as pd\n# def process_large_csv(input_csv, output_csv=None, dataset_type=\"val\"):\n#     \"\"\"\n#     Reads a large CSV file, extracts required columns, modifies the image_path \n#     by removing dataset-specific prefixes and adding the correct directory,\n#     and optionally saves the processed DataFrame.\n    \n#     Parameters:\n#     - input_csv (str): Path to the input CSV file.\n#     - output_csv (str, optional): Path to save the processed CSV file. If None, it won't save.\n#     - dataset_type (str): Type of dataset ('train', 'test', 'val') to determine path adjustments.\n    \n#     Returns:\n#     - pd.DataFrame: Processed DataFrame with updated image paths.\n#     \"\"\"\n#     #use_cols = [\"image_path\", \"caption\"]  # Load only needed columns\n\n#     # Read CSV with only required columns\n#     df = pd.read_csv(input_csv)\n\n#     # Define path mappings based on dataset type\n#     path_mappings = {\n#         \"train\": (\"output_frames/\", \"/kaggle/input/uca-ucf-dataset/train_ucf_output/\"),\n#         \"test\": (\"output_frames/\", \"/kaggle/input/uca-ucf-dataset/test_ucf_output/\"),\n#         \"val\": (\"val_output_frames/\", \"/kaggle/input/uca-ucf-dataset/Val_ucf_output/\")\n#     }\n\n#     # Get the correct replacement values\n#     remove_prefix, new_prefix = path_mappings.get(dataset_type, (\"\", \"\"))\n\n#     # Remove the dataset-specific prefix and add the correct directory\n#     df[\"image_path\"] = df[\"image_path\"].str.replace(remove_prefix, \"\", regex=False)\n#     df[\"image_path\"] = new_prefix + df[\"image_path\"]\n\n#     # Save the processed DataFrame if an output path is provided\n#     if output_csv:\n#         df.to_csv(output_csv, index=False)\n\n#     return df\n\n# # Process train, test, and validation datasets with the correct path adjustments\n# train_df = process_large_csv(\"/kaggle/input/uca-ucf-dataset/train_image_captions (2).csv\", \n#                              \"train_ucf_set.csv\", dataset_type=\"train\")\n# test_df = process_large_csv(\"/kaggle/input/uca-ucf-dataset/test_image_captions.csv\", \n#                             \"test_ucf_set.csv\", dataset_type=\"test\")\n# valid_df = process_large_csv(\"/kaggle/input/uca-ucf-dataset/Val_image_captions.csv\", \n#                              \"valid_ucf_set.csv\", dataset_type=\"val\")\n\n# train_df  # Display first few rows\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:00:49.142676Z","iopub.execute_input":"2025-03-26T18:00:49.142975Z","iopub.status.idle":"2025-03-26T18:00:50.913999Z","shell.execute_reply.started":"2025-03-26T18:00:49.142954Z","shell.execute_reply":"2025-03-26T18:00:50.913178Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                              image_path  \\\n0      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n1      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n2      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n3      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n4      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n...                                                  ...   \n90382  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90383  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90384  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90385  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90386  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n\n                                                 caption  \\\n0      A woman with short hair, slightly fat, wearing...   \n1      A woman with short hair, slightly fat, wearing...   \n2      A woman with short hair, slightly fat, wearing...   \n3      A woman with short hair, slightly fat, wearing...   \n4      A woman with short hair, slightly fat, wearing...   \n...                                                  ...   \n90382                       walked past a woman in white   \n90383                       walked past a woman in white   \n90384                       walked past a woman in white   \n90385                       walked past a woman in white   \n90386                       walked past a woman in white   \n\n                    video_key category  frame_index  \n0               Abuse001_x264    Abuse            0  \n1               Abuse001_x264    Abuse           20  \n2               Abuse001_x264    Abuse           40  \n3               Abuse001_x264    Abuse           60  \n4               Abuse001_x264    Abuse           80  \n...                       ...      ...          ...  \n90382  Normal_Videos_897_x264   Normal          560  \n90383  Normal_Videos_897_x264   Normal          580  \n90384  Normal_Videos_897_x264   Normal          600  \n90385  Normal_Videos_897_x264   Normal          620  \n90386  Normal_Videos_897_x264   Normal          640  \n\n[90387 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>video_key</th>\n      <th>category</th>\n      <th>frame_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>A woman with short hair, slightly fat, wearing...</td>\n      <td>Abuse001_x264</td>\n      <td>Abuse</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>A woman with short hair, slightly fat, wearing...</td>\n      <td>Abuse001_x264</td>\n      <td>Abuse</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>A woman with short hair, slightly fat, wearing...</td>\n      <td>Abuse001_x264</td>\n      <td>Abuse</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>A woman with short hair, slightly fat, wearing...</td>\n      <td>Abuse001_x264</td>\n      <td>Abuse</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>A woman with short hair, slightly fat, wearing...</td>\n      <td>Abuse001_x264</td>\n      <td>Abuse</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90382</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>walked past a woman in white</td>\n      <td>Normal_Videos_897_x264</td>\n      <td>Normal</td>\n      <td>560</td>\n    </tr>\n    <tr>\n      <th>90383</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>walked past a woman in white</td>\n      <td>Normal_Videos_897_x264</td>\n      <td>Normal</td>\n      <td>580</td>\n    </tr>\n    <tr>\n      <th>90384</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>walked past a woman in white</td>\n      <td>Normal_Videos_897_x264</td>\n      <td>Normal</td>\n      <td>600</td>\n    </tr>\n    <tr>\n      <th>90385</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>walked past a woman in white</td>\n      <td>Normal_Videos_897_x264</td>\n      <td>Normal</td>\n      <td>620</td>\n    </tr>\n    <tr>\n      <th>90386</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>walked past a woman in white</td>\n      <td>Normal_Videos_897_x264</td>\n      <td>Normal</td>\n      <td>640</td>\n    </tr>\n  </tbody>\n</table>\n<p>90387 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# Splitting into Train, Test and Valid sets","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# # Read the CSV file into a DataFrame\n# ds1= pd.read_csv('/kaggle/input/ucf-small-dataset/train_image_captions.csv')\n# ds2= pd.read_csv('/kaggle/input/ucf-small-dataset/val_image_captions.csv')\n# ds3= pd.read_csv('/kaggle/input/ucf-small-dataset/test_image_captions.csv')\n\ncombined_df = pd.concat([ds1, ds2, ds3], axis=0, ignore_index=True)\nprint(combined_df)\n# # Now df contains the data from the CSV file\n# train_fl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:59:46.277193Z","iopub.execute_input":"2025-03-26T17:59:46.277560Z","iopub.status.idle":"2025-03-26T17:59:46.292125Z","shell.execute_reply.started":"2025-03-26T17:59:46.277533Z","shell.execute_reply":"2025-03-26T17:59:46.291436Z"}},"outputs":[{"name":"stdout","text":"                                               image_path  \\\n0       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n1       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n2       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n3       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n4       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n...                                                   ...   \n244198  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n244199  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n244200  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n244201  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n244202  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n\n                                                  caption  \\\n0       A woman with short hair, slightly fat, wearing...   \n1       A woman with short hair, slightly fat, wearing...   \n2       A woman with short hair, slightly fat, wearing...   \n3       A woman with short hair, slightly fat, wearing...   \n4       A woman with short hair, slightly fat, wearing...   \n...                                                   ...   \n244198  A woman wearing green half-sleeves on the left...   \n244199  A woman wearing green half-sleeves on the left...   \n244200  A woman wearing green half-sleeves on the left...   \n244201  A woman wearing green half-sleeves on the left...   \n244202  A woman wearing green half-sleeves on the left...   \n\n                    video_key category  frame_index  \n0               Abuse001_x264    Abuse            0  \n1               Abuse001_x264    Abuse           20  \n2               Abuse001_x264    Abuse           40  \n3               Abuse001_x264    Abuse           60  \n4               Abuse001_x264    Abuse           80  \n...                       ...      ...          ...  \n244198  Normal_Videos756_x264   Normal          460  \n244199  Normal_Videos756_x264   Normal          480  \n244200  Normal_Videos756_x264   Normal          500  \n244201  Normal_Videos756_x264   Normal          520  \n244202  Normal_Videos756_x264   Normal          540  \n\n[244203 rows x 5 columns]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.model_selection import train_test_split\n# import numpy as np\n\n# # Example: load your dataset\n# # Assuming your dataset is in a CSV file named 'dataset.csv'\n# df = combined_df\n\n# # Initialize empty DataFrames for each split\n# train_df = pd.DataFrame()\n# test_df = pd.DataFrame()\n# valid_df = pd.DataFrame()\n\n# # Define split percentages\n# train_pct = 0.3\n# # For the remaining 30%, you might split equally into test and valid (15% each)\n# # Alternatively, adjust as needed:\n# test_pct = 0.3\n# valid_pct = 0.3\n\n# # Process each category separately\n# for cat in df['category'].unique():\n#     cat_df = df[df['category'] == cat]\n#     # Get unique video_keys within this category\n#     video_keys = cat_df['video_key'].unique()\n#     # Shuffle video_keys for random split (set random_state for reproducibility)\n#     np.random.seed(42)\n#     np.random.shuffle(video_keys)\n    \n#     n_total = len(video_keys)\n#     n_train = int(train_pct * n_total)\n#     n_test = int(test_pct * n_total)\n#     # The remaining keys go to validation (or adjust if you want a different ratio)\n    \n#     train_keys = video_keys[:n_train]\n#     test_keys = video_keys[n_train:n_train+n_test]\n#     valid_keys = video_keys[n_train+n_test:]\n    \n#     # Assign all rows corresponding to these video_keys\n#     train_df = pd.concat([train_df, cat_df[cat_df['video_key'].isin(train_keys)]])\n#     test_df = pd.concat([test_df, cat_df[cat_df['video_key'].isin(test_keys)]])\n#     valid_df = pd.concat([valid_df, cat_df[cat_df['video_key'].isin(valid_keys)]])\n    \n# # Optionally, shuffle the final DataFrames\n# train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n# test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n# valid_df = valid_df.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# # Now train_df, test_df, and valid_df are your splits where each video_key remains intact.\n# print(\"Train set shape:\", train_df.shape)\n# print(\"Test set shape:\", test_df.shape)\n# print(\"Validation set shape:\", valid_df.shape)\n\n# # You can then save the splits to files if needed:\n# train_df.to_csv('train_split.csv', index=False)\n# test_df.to_csv('test_split.csv', index=False)\n# valid_df.to_csv('valid_split.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:58:42.588067Z","iopub.execute_input":"2025-03-26T17:58:42.588413Z","iopub.status.idle":"2025-03-26T17:58:44.246941Z","shell.execute_reply.started":"2025-03-26T17:58:42.588386Z","shell.execute_reply":"2025-03-26T17:58:44.246011Z"}},"outputs":[{"name":"stdout","text":"Train set shape: (83705, 5)\nTest set shape: (69554, 5)\nValidation set shape: (90944, 5)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Hugging Face login","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:50:22.113407Z","iopub.execute_input":"2025-03-26T17:50:22.113631Z","iopub.status.idle":"2025-03-26T17:50:22.463546Z","shell.execute_reply.started":"2025-03-26T17:50:22.113607Z","shell.execute_reply":"2025-03-26T17:50:22.462698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8357d5944e064e3096d9fe0bc5566f5f"}},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Install needed Packages","metadata":{}},{"cell_type":"code","source":"!pip install datasets\n!pip install accelerate\n!pip install transformers\n!pip install pycocotools","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:50:22.464594Z","iopub.execute_input":"2025-03-26T17:50:22.464901Z","iopub.status.idle":"2025-03-26T17:50:36.704780Z","shell.execute_reply.started":"2025-03-26T17:50:22.464870Z","shell.execute_reply":"2025-03-26T17:50:36.703917Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.29.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\nRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->pycocotools) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->pycocotools) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->pycocotools) (2024.2.0)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Mixing Dataframe","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming your DataFrame is named df\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\nvalid_df = valid_df.sample(frac=1).reset_index(drop=True)\ntest_df = test_df.sample(frac=1).reset_index(drop=True)\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:00:55.441269Z","iopub.execute_input":"2025-03-26T18:00:55.441589Z","iopub.status.idle":"2025-03-26T18:00:55.518123Z","shell.execute_reply.started":"2025-03-26T18:00:55.441562Z","shell.execute_reply":"2025-03-26T18:00:55.517168Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              image_path  \\\n0      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n1      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n2      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n3      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n4      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n...                                                  ...   \n90382  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90383  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90384  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90385  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n90386  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n\n                                                 caption            video_key  \\\n0      Three policemen came to the door, one walked i...        Abuse008_x264   \n1                 Many vehicles are driving on the road.       Arrest015_x264   \n2       Multiple firefighters were holding water pipe...    Explosion046_x264   \n3        The big man kept slashing at his head and body.      Assault004_x264   \n4                                  Two men had a quarrel     Fighting010_x264   \n...                                                  ...                  ...   \n90382  The woman in gray pulled away the man in the j...     Fighting004_x264   \n90383  The camera changes the perspective, and the ma...      Robbery021_x264   \n90384  The woman in the black and white skirt picked ...  Shoplifting014_x264   \n90385  The man walked around the sofa and came to a d...     Burglary040_x264   \n90386  There were several people talking together in ...    Explosion046_x264   \n\n          category  frame_index  \n0            Abuse         7420  \n1           Arrest          480  \n2        Explosion        30220  \n3          Assault          840  \n4         Fighting         1740  \n...            ...          ...  \n90382     Fighting         7600  \n90383      Robbery          620  \n90384  Shoplifting        16100  \n90385     Burglary         2400  \n90386    Explosion        73300  \n\n[90387 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>video_key</th>\n      <th>category</th>\n      <th>frame_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>Three policemen came to the door, one walked i...</td>\n      <td>Abuse008_x264</td>\n      <td>Abuse</td>\n      <td>7420</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>Many vehicles are driving on the road.</td>\n      <td>Arrest015_x264</td>\n      <td>Arrest</td>\n      <td>480</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>Multiple firefighters were holding water pipe...</td>\n      <td>Explosion046_x264</td>\n      <td>Explosion</td>\n      <td>30220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>The big man kept slashing at his head and body.</td>\n      <td>Assault004_x264</td>\n      <td>Assault</td>\n      <td>840</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>Two men had a quarrel</td>\n      <td>Fighting010_x264</td>\n      <td>Fighting</td>\n      <td>1740</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90382</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>The woman in gray pulled away the man in the j...</td>\n      <td>Fighting004_x264</td>\n      <td>Fighting</td>\n      <td>7600</td>\n    </tr>\n    <tr>\n      <th>90383</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>The camera changes the perspective, and the ma...</td>\n      <td>Robbery021_x264</td>\n      <td>Robbery</td>\n      <td>620</td>\n    </tr>\n    <tr>\n      <th>90384</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>The woman in the black and white skirt picked ...</td>\n      <td>Shoplifting014_x264</td>\n      <td>Shoplifting</td>\n      <td>16100</td>\n    </tr>\n    <tr>\n      <th>90385</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>The man walked around the sofa and came to a d...</td>\n      <td>Burglary040_x264</td>\n      <td>Burglary</td>\n      <td>2400</td>\n    </tr>\n    <tr>\n      <th>90386</th>\n      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n      <td>There were several people talking together in ...</td>\n      <td>Explosion046_x264</td>\n      <td>Explosion</td>\n      <td>73300</td>\n    </tr>\n  </tbody>\n</table>\n<p>90387 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"valid_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:37:29.146882Z","iopub.execute_input":"2025-03-26T18:37:29.147169Z","iopub.status.idle":"2025-03-26T18:37:29.157835Z","shell.execute_reply.started":"2025-03-26T18:37:29.147146Z","shell.execute_reply":"2025-03-26T18:37:29.156964Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                              image_path  \\\n0      /kaggle/input/uca-ucf-dataset/Val_ucf_output/F...   \n1      /kaggle/input/uca-ucf-dataset/Val_ucf_output/F...   \n2      /kaggle/input/uca-ucf-dataset/Val_ucf_output/R...   \n3      /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n4      /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n...                                                  ...   \n53043  /kaggle/input/uca-ucf-dataset/Val_ucf_output/F...   \n53044  /kaggle/input/uca-ucf-dataset/Val_ucf_output/S...   \n53045  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n53046  /kaggle/input/uca-ucf-dataset/Val_ucf_output/R...   \n53047  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n\n                                                 caption  \\\n0      Another man stood up to help pack things, and ...   \n1      Two people were arguing in the middle of the r...   \n2      The man reached for the money and then opened ...   \n3      The bald man quickly walked away from the shel...   \n4      A woman in a gray coat walked by, then turned ...   \n...                                                  ...   \n53043  A man set up his bicycle for the man to ride a...   \n53044         The silver car continued to move backwards   \n53045  The man in the red hat chats with the man in blue   \n53046  The two worked together to suppress and beat t...   \n53047                  A group of people enter the house   \n\n                   video_key  category  frame_index  \n0           Fighting050_x264  Fighting        22560  \n1           Fighting048_x264  Fighting         3580  \n2            Robbery143_x264   Robbery          700  \n3      Normal_Videos689_x264    Normal         8320  \n4      Normal_Videos676_x264    Normal         2660  \n...                      ...       ...          ...  \n53043       Fighting048_x264  Fighting         5620  \n53044       Stealing109_x264  Stealing         1080  \n53045  Normal_Videos689_x264    Normal        11240  \n53046        Robbery127_x264   Robbery          500  \n53047  Normal_Videos681_x264    Normal         9280  \n\n[53048 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>caption</th>\n      <th>video_key</th>\n      <th>category</th>\n      <th>frame_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/F...</td>\n      <td>Another man stood up to help pack things, and ...</td>\n      <td>Fighting050_x264</td>\n      <td>Fighting</td>\n      <td>22560</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/F...</td>\n      <td>Two people were arguing in the middle of the r...</td>\n      <td>Fighting048_x264</td>\n      <td>Fighting</td>\n      <td>3580</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/R...</td>\n      <td>The man reached for the money and then opened ...</td>\n      <td>Robbery143_x264</td>\n      <td>Robbery</td>\n      <td>700</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n      <td>The bald man quickly walked away from the shel...</td>\n      <td>Normal_Videos689_x264</td>\n      <td>Normal</td>\n      <td>8320</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n      <td>A woman in a gray coat walked by, then turned ...</td>\n      <td>Normal_Videos676_x264</td>\n      <td>Normal</td>\n      <td>2660</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53043</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/F...</td>\n      <td>A man set up his bicycle for the man to ride a...</td>\n      <td>Fighting048_x264</td>\n      <td>Fighting</td>\n      <td>5620</td>\n    </tr>\n    <tr>\n      <th>53044</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/S...</td>\n      <td>The silver car continued to move backwards</td>\n      <td>Stealing109_x264</td>\n      <td>Stealing</td>\n      <td>1080</td>\n    </tr>\n    <tr>\n      <th>53045</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n      <td>The man in the red hat chats with the man in blue</td>\n      <td>Normal_Videos689_x264</td>\n      <td>Normal</td>\n      <td>11240</td>\n    </tr>\n    <tr>\n      <th>53046</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/R...</td>\n      <td>The two worked together to suppress and beat t...</td>\n      <td>Robbery127_x264</td>\n      <td>Robbery</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>53047</th>\n      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n      <td>A group of people enter the house</td>\n      <td>Normal_Videos681_x264</td>\n      <td>Normal</td>\n      <td>9280</td>\n    </tr>\n  </tbody>\n</table>\n<p>53048 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming your DataFrame is named ds\ntrain_df.to_csv('Train_ds.csv', index=False)\nvalid_df.to_csv('Valid_ds.csv', index=False)\ntest_df.to_csv('Test_ds.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:01:24.538668Z","iopub.execute_input":"2025-03-26T18:01:24.538965Z","iopub.status.idle":"2025-03-26T18:01:25.770314Z","shell.execute_reply.started":"2025-03-26T18:01:24.538943Z","shell.execute_reply":"2025-03-26T18:01:25.769358Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# # Read the CSV file into a DataFrame\n# train_df = pd.read_csv('/kaggle/input/uca-ucf-dataset/Train_ds (3).csv')\n# valid_df= pd.read_csv('/kaggle/input/uca-ucf-dataset/Valid_ds (3).csv')\n# test_df = pd.read_csv('/kaggle/input/uca-ucf-dataset/Test_ds (3).csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:50:37.984929Z","iopub.execute_input":"2025-03-26T17:50:37.985173Z","iopub.status.idle":"2025-03-26T17:50:37.988102Z","shell.execute_reply.started":"2025-03-26T17:50:37.985153Z","shell.execute_reply":"2025-03-26T17:50:37.987423Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\n# Convert each split into a Dataset object\ntrain_datads = Dataset.from_pandas(train_df)\nvalid_datads = Dataset.from_pandas(valid_df[:10000])\ntest_datads = Dataset.from_pandas(test_df)\n\n# Organize the splits into a DatasetDict\nds = DatasetDict({\n    \"train\": train_datads,\n    \"validation\": valid_datads,\n    \"test\": test_datads\n})\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:37:53.637858Z","iopub.execute_input":"2025-03-26T18:37:53.638153Z","iopub.status.idle":"2025-03-26T18:37:54.010556Z","shell.execute_reply.started":"2025-03-26T18:37:53.638131Z","shell.execute_reply":"2025-03-26T18:37:54.009843Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['image_path', 'caption', 'video_key', 'category', 'frame_index'],\n        num_rows: 90387\n    })\n    validation: Dataset({\n        features: ['image_path', 'caption', 'video_key', 'category', 'frame_index'],\n        num_rows: 10000\n    })\n    test: Dataset({\n        features: ['image_path', 'caption', 'video_key', 'category', 'frame_index'],\n        num_rows: 100768\n    })\n})"},"metadata":{}}],"execution_count":33},{"cell_type":"markdown","source":"# Initialize VisionEncoderDecoderModel","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nfrom transformers import AutoTokenizer, AutoFeatureExtractor\nfrom transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor, ViTImageProcessor\nfrom datasets import DatasetDict\n\n# Initialize tokenizer and feature extractor (replace 'model_name' with your model's name)\n#tokenizer = AutoTokenizer.from_pretrained('model_name')\n#feature_extractor = AutoFeatureExtractor.from_pretrained('model_name')\nmodel_name=\"NourFakih/Vit-GPT2-COCO2017Flickr-85k-09\"\nmodel = VisionEncoderDecoderModel.from_pretrained(model_name)\nfeature_extractor = ViTImageProcessor.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n# GPT2 only has bos/eos tokens but not decoder_start/pad tokens\ntokenizer.pad_token = tokenizer.eos_token\n\n# update the model config\nmodel.config.eos_token_id = tokenizer.eos_token_id\nmodel.config.decoder_start_token_id = tokenizer.bos_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\noutput_dir = \"vit-gpt2-model\"\nmodel.save_pretrained(output_dir)\nfeature_extractor.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:50:39.743038Z","iopub.execute_input":"2025-03-26T17:50:39.743633Z","iopub.status.idle":"2025-03-26T17:51:44.603101Z","shell.execute_reply.started":"2025-03-26T17:50:39.743600Z","shell.execute_reply":"2025-03-26T17:51:44.602176Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd6f3b1993d24660b449c171976393dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/957M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf7562ba3be4af9815df7e9354cd141"}},"metadata":{}},{"name":"stderr","text":"Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n  \"architectures\": [\n    \"ViTModel\"\n  ],\n  \"attention_probs_dropout_prob\": 0.0,\n  \"encoder_stride\": 16,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.0,\n  \"hidden_size\": 768,\n  \"image_size\": 224,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"model_type\": \"vit\",\n  \"num_attention_heads\": 12,\n  \"num_channels\": 3,\n  \"num_hidden_layers\": 12,\n  \"patch_size\": 16,\n  \"qkv_bias\": true,\n  \"transformers_version\": \"4.47.0\"\n}\n\nConfig of the decoder: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'> is overwritten by shared decoder config: GPT2Config {\n  \"activation_function\": \"gelu_new\",\n  \"add_cross_attention\": true,\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"decoder_start_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"initializer_range\": 0.02,\n  \"is_decoder\": true,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"pad_token_id\": 50256,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.47.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50257\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/149 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20fa162e50b543f28eb5b077b6863746"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06d117dbb4bb4e168358524310719649"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5684275577447c939ccde5c9a888ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2fa3546fc6843f4945a1a6998d9eea8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f222b7fc7cf44a89347c1675ebf7530"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4d02e774404b8aa1ecd30711411326"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/473 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a52bbac53f4c02872ace702bcfddf0"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('vit-gpt2-model/tokenizer_config.json',\n 'vit-gpt2-model/special_tokens_map.json',\n 'vit-gpt2-model/vocab.json',\n 'vit-gpt2-model/merges.txt',\n 'vit-gpt2-model/added_tokens.json',\n 'vit-gpt2-model/tokenizer.json')"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# WANDB_DISABLED and nltk","metadata":{}},{"cell_type":"code","source":"import os\nimport datasets\nfrom transformers import VisionEncoderDecoderModel, AutoFeatureExtractor,AutoTokenizer\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nimport nltk\ntry:\n    nltk.data.find(\"tokenizers/punkt\")\nexcept (LookupError, OSError):\n    nltk.download(\"punkt\", quiet=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:51:44.604069Z","iopub.execute_input":"2025-03-26T17:51:44.604841Z","iopub.status.idle":"2025-03-26T17:51:45.579444Z","shell.execute_reply.started":"2025-03-26T17:51:44.604808Z","shell.execute_reply":"2025-03-26T17:51:45.578550Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Define Metric","metadata":{}},{"cell_type":"code","source":"!pip install rouge_score\n!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:51:45.580375Z","iopub.execute_input":"2025-03-26T17:51:45.580621Z","iopub.status.idle":"2025-03-26T17:51:57.194726Z","shell.execute_reply.started":"2025-03-26T17:51:45.580601Z","shell.execute_reply":"2025-03-26T17:51:57.193615Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=386ed069b17a4a2a57ea84ddb832051d824c30c1b633449b91daa6a9d34f44bf\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import evaluate\nmetric = evaluate.load(\"rouge\")\n\nimport numpy as np\n\nignore_pad_token_for_loss = True\n\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n\n    return preds, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:51:57.195911Z","iopub.execute_input":"2025-03-26T17:51:57.196177Z","iopub.status.idle":"2025-03-26T17:51:59.118252Z","shell.execute_reply.started":"2025-03-26T17:51:57.196151Z","shell.execute_reply":"2025-03-26T17:51:59.117637Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5559f7faa01a408aa7e99860261b774a"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n\n    # Ensure preds is a NumPy array\n    if isinstance(preds, torch.Tensor):\n        preds = preds.cpu().numpy()\n\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    # Debugging\n    print(\"Preds before decoding:\", preds)\n    \n    # Ensure valid token IDs\n    preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    if ignore_pad_token_for_loss:\n        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {k: round(v * 100, 4) for k, v in result.items()}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return result\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:51:59.119118Z","iopub.execute_input":"2025-03-26T17:51:59.119441Z","iopub.status.idle":"2025-03-26T17:51:59.125296Z","shell.execute_reply.started":"2025-03-26T17:51:59.119410Z","shell.execute_reply":"2025-03-26T17:51:59.124378Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Preparing Dataset for Training","metadata":{}},{"cell_type":"code","source":"import torch\nfrom PIL import Image\n# Fix attention mask issue by explicitly setting pad token\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token  # Set pad_token to eos_token to prevent warnings\n\n\nclass ImageCapatioingDataset(torch.utils.data.Dataset):\n    def __init__(self, ds, ds_type, max_target_length):\n        self.ds = ds\n        self.max_target_length = max_target_length\n        self.ds_type = ds_type\n\n    def __getitem__(self, idx):\n        image_path = self.ds[self.ds_type]['image_path'][idx]\n        caption = self.ds[self.ds_type]['caption'][idx]\n        model_inputs = dict()\n        model_inputs['labels'] = self.tokenization_fn(caption, self.max_target_length)\n        model_inputs['pixel_values'] = self.feature_extraction_fn(image_path)\n        return model_inputs\n\n    def __len__(self):\n        return len(self.ds[self.ds_type])\n    \n    # text preprocessing step\n    def tokenization_fn(self, caption, max_target_length):\n        \"\"\"Run tokenization on caption.\"\"\"\n        labels = tokenizer(caption, \n                          padding=\"max_length\", \n                          max_length=max_target_length).input_ids\n\n        return labels\n    \n    # image preprocessing step\n    def feature_extraction_fn(self, image_path):\n        \"\"\"\n        Run feature extraction on images\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n        image = Image.open(image_path).convert(\"RGB\")\n        image = image.resize((224, 224))\n\n        encoder_inputs = feature_extractor(images=image, return_tensors=\"np\")\n\n        return encoder_inputs.pixel_values[0]\n\n\ntrain_ds = ImageCapatioingDataset(ds, 'train', 256)\neval_ds = ImageCapatioingDataset(ds, 'validation', 256)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:01:34.847730Z","iopub.execute_input":"2025-03-26T18:01:34.848060Z","iopub.status.idle":"2025-03-26T18:01:34.855099Z","shell.execute_reply.started":"2025-03-26T18:01:34.848033Z","shell.execute_reply":"2025-03-26T18:01:34.854118Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\noutput_dir=\"./Vit-GPT2-UCA-UCF-06\"\nhub_model_id=\"NourFakih/Vit-GPT2-UCA-UCF-06\"\ntraining_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    save_steps=500,\n    eval_steps=500,\n    eval_strategy=\"steps\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=4,\n    output_dir=output_dir,\n    overwrite_output_dir=True,\n    #evaluation_strategy=\"steps\",\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    #tpu_num_cores\n    #accelerator_config (str, dict, or AcceleratorConfig, optional),\n    push_to_hub=True,\n    hub_strategy=\"all_checkpoints\",\n    #resume_from_checkpoint=\"./Vit-GPT2-UCA-UCF-05/checkpoint-500\",\n    hub_always_push=True,\n    hub_model_id=hub_model_id\n)\nfrom transformers import default_data_collator\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    train_dataset=train_ds,\n    eval_dataset=eval_ds,\n    data_collator=default_data_collator,\n)\ntrainer.train()\ntrainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:38:14.646143Z","iopub.execute_input":"2025-03-26T18:38:14.646456Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n<ipython-input-34-8191b409b71b>:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='43' max='16947' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   43/16947 02:38 < 18:08:33, 0.26 it/s, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"# Push to HuggingFace","metadata":{}},{"cell_type":"code","source":"trainer.save_model(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:52:01.894254Z","iopub.status.idle":"2025-03-26T17:52:01.894655Z","shell.execute_reply":"2025-03-26T17:52:01.894477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.save_pretrained(output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:52:01.895390Z","iopub.status.idle":"2025-03-26T17:52:01.895771Z","shell.execute_reply":"2025-03-26T17:52:01.895605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.push_to_hub(hub_model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:52:01.896768Z","iopub.status.idle":"2025-03-26T17:52:01.897096Z","shell.execute_reply":"2025-03-26T17:52:01.896965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_extractor.push_to_hub(hub_model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:52:01.897837Z","iopub.status.idle":"2025-03-26T17:52:01.898076Z","shell.execute_reply":"2025-03-26T17:52:01.897977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_extractor.save_pretrained(output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:52:01.899029Z","iopub.status.idle":"2025-03-26T17:52:01.899432Z","shell.execute_reply":"2025-03-26T17:52:01.899256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:52:01.900140Z","iopub.status.idle":"2025-03-26T17:52:01.900421Z","shell.execute_reply":"2025-03-26T17:52:01.900314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.push_to_hub(hub_model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T17:52:01.901353Z","iopub.status.idle":"2025-03-26T17:52:01.901688Z","shell.execute_reply":"2025-03-26T17:52:01.901525Z"}},"outputs":[],"execution_count":null}]}