{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**NoteBook Summary**\n",
    "\n",
    "This comprehensive notebook orchestrates the processing, preparation, and training of a VisionEncoderDecoder model (ViT-GPT2) for generating natural language captions on surveillance imagery from the UCF-Crime dataset. The workflow starts by cleaning and remapping image paths for different dataset splits (train/val/test) from both the UCF-Small and UCF-UCA datasets. Data is stratified by video category and key to ensure consistent and balanced splits. The processed data is wrapped into Hugging Face-compatible DatasetDict objects. Next, the notebook loads a pretrained ViT-GPT2 model, configures tokenizer and feature extractor settings, and defines a PyTorch Dataset class that tokenizes captions and extracts image features. Evaluation metrics like ROUGE are configured using Hugging Face's evaluate library and NLTK preprocessing. Finally, using Seq2SeqTrainer, the model is trained with checkpointing and Hugging Face Hub integration for versioning. The trained model, tokenizer, and feature extractor are pushed to the Hugging Face Hub for public access and reuse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process UCF-Small_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:50:17.452791Z",
     "iopub.status.busy": "2025-03-26T17:50:17.452514Z",
     "iopub.status.idle": "2025-03-26T17:50:17.849218Z",
     "shell.execute_reply": "2025-03-26T17:50:17.848370Z",
     "shell.execute_reply.started": "2025-03-26T17:50:17.452761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>video_key</th>\n",
       "      <th>category</th>\n",
       "      <th>frame_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>A police car drove into a grassy field</td>\n",
       "      <td>Abuse006_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The police car stopped, and two police officer...</td>\n",
       "      <td>Abuse006_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The police car stopped, and two police officer...</td>\n",
       "      <td>Abuse006_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The police car stopped, and two police officer...</td>\n",
       "      <td>Abuse006_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The police car stopped, and two police officer...</td>\n",
       "      <td>Abuse006_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The lights in the room turned on, someone was ...</td>\n",
       "      <td>Normal_Videos031_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The room is illuminated by light, and the shel...</td>\n",
       "      <td>Normal_Videos031_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The lights in the room are off, and there are ...</td>\n",
       "      <td>Normal_Videos031_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>3294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The lights in the room are off, and there are ...</td>\n",
       "      <td>Normal_Videos031_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>3294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>/kaggle/input/ucf-small-dataset/train_ucf_outp...</td>\n",
       "      <td>The lights in the room are on, there are many ...</td>\n",
       "      <td>Normal_Videos031_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>3313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  \\\n",
       "0     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "1     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "2     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "3     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "4     /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "...                                                 ...   \n",
       "1038  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "1039  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "1040  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "1041  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "1042  /kaggle/input/ucf-small-dataset/train_ucf_outp...   \n",
       "\n",
       "                                                caption  \\\n",
       "0                A police car drove into a grassy field   \n",
       "1     The police car stopped, and two police officer...   \n",
       "2     The police car stopped, and two police officer...   \n",
       "3     The police car stopped, and two police officer...   \n",
       "4     The police car stopped, and two police officer...   \n",
       "...                                                 ...   \n",
       "1038  The lights in the room turned on, someone was ...   \n",
       "1039  The room is illuminated by light, and the shel...   \n",
       "1040  The lights in the room are off, and there are ...   \n",
       "1041  The lights in the room are off, and there are ...   \n",
       "1042  The lights in the room are on, there are many ...   \n",
       "\n",
       "                  video_key category  frame_index  \n",
       "0             Abuse006_x264    Abuse          141  \n",
       "1             Abuse006_x264    Abuse          283  \n",
       "2             Abuse006_x264    Abuse          283  \n",
       "3             Abuse006_x264    Abuse          296  \n",
       "4             Abuse006_x264    Abuse          309  \n",
       "...                     ...      ...          ...  \n",
       "1038  Normal_Videos031_x264   Normal         2611  \n",
       "1039  Normal_Videos031_x264   Normal         2952  \n",
       "1040  Normal_Videos031_x264   Normal         3294  \n",
       "1041  Normal_Videos031_x264   Normal         3294  \n",
       "1042  Normal_Videos031_x264   Normal         3313  \n",
       "\n",
       "[1043 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_large_csv(input_csv, output_csv=None, dataset_type=\"val\"):\n",
    "    \"\"\"\n",
    "    Reads a large CSV file, extracts required columns, modifies the image_path \n",
    "    by removing dataset-specific prefixes and adding the correct directory,\n",
    "    and optionally saves the processed DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_csv (str): Path to the input CSV file.\n",
    "    - output_csv (str, optional): Path to save the processed CSV file. If None, it won't save.\n",
    "    - dataset_type (str): Type of dataset ('train', 'test', 'val') to determine path adjustments.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed DataFrame with updated image paths.\n",
    "    \"\"\"\n",
    "    #use_cols = [\"image_path\", \"caption\"]  # Load only needed columns\n",
    "\n",
    "    # Read CSV with only required columns\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Define path mappings based on dataset type\n",
    "    path_mappings = {\n",
    "        \"train\": (\"train_output_frames/\", \"/kaggle/input/ucf-small-dataset/train_ucf_output/\"),\n",
    "        \"test\": (\"test_output_frames/\", \"/kaggle/input/ucf-small-dataset/test_ucf_output/\"),\n",
    "        \"val\": (\"val_output_frames/\", \"/kaggle/input/ucf-small-dataset/val_ucf_output/\")\n",
    "    }\n",
    "\n",
    "    # Get the correct replacement values\n",
    "    remove_prefix, new_prefix = path_mappings.get(dataset_type, (\"\", \"\"))\n",
    "\n",
    "    # Remove the dataset-specific prefix and add the correct directory\n",
    "    df[\"image_path\"] = df[\"image_path\"].str.replace(remove_prefix, \"\", regex=False)\n",
    "    df[\"image_path\"] = new_prefix + df[\"image_path\"]\n",
    "\n",
    "    # Save the processed DataFrame if an output path is provided\n",
    "    if output_csv:\n",
    "        df.to_csv(output_csv, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process train, test, and validation datasets with the correct path adjustments\n",
    "ds1 = process_large_csv(\"/kaggle/input/ucf-small-dataset/train_image_captions.csv\", \n",
    "                             \"train_ucf_set.csv\", dataset_type=\"train\")\n",
    "ds2 = process_large_csv(\"/kaggle/input/ucf-small-dataset/test_image_captions.csv\", \n",
    "                            \"test_ucf_set.csv\", dataset_type=\"test\")\n",
    "ds3 = process_large_csv(\"/kaggle/input/ucf-small-dataset/val_image_captions.csv\", \n",
    "                             \"valid_ucf_set.csv\", dataset_type=\"val\")\n",
    "\n",
    "# train_ds  # Display first few rows\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the full dataset\n",
    "df = pd.read_csv('/kaggle/input/ucf-crime-extracted-frames/test_image_captions.csv)\n",
    "\n",
    "# Initialize split containers\n",
    "train_list, val_list, test_list = [], [], []\n",
    "\n",
    "# Group by category\n",
    "for category, group in df.groupby('category'):\n",
    "    # Get all unique videos in this category\n",
    "    video_keys = group['video_key'].unique()\n",
    "    \n",
    "    # Split into train (65%) and temp (35%)\n",
    "    train_videos, temp_videos = train_test_split(\n",
    "        video_keys, test_size=0.35, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Split temp into val (15%) and test (20%)\n",
    "    val_videos, test_videos = train_test_split(\n",
    "        temp_videos,\n",
    "        test_size=(20 / 35),  # Adjusted for original total\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Get dataframes for each split\n",
    "    train_list.append(group[group['video_key'].isin(train_videos)])\n",
    "    val_list.append(group[group['video_key'].isin(val_videos)])\n",
    "    test_list.append(group[group['video_key'].isin(test_videos)])\n",
    "\n",
    "# Concatenate all splits\n",
    "train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "val_df = pd.concat(val_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "# Save splits\n",
    "train_df.to_csv('train_image_captions.csv', index=False)\n",
    "val_df.to_csv('val_image_captions.csv', index=False)\n",
    "test_df.to_csv('test_image_captions.csv', index=False)\n",
    "\n",
    "print(f\"Train: {len(train_df)} samples\")\n",
    "print(f\"Val: {len(val_df)} samples\")\n",
    "print(f\"Test: {len(test_df)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process UCF-UCA-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:00:49.142975Z",
     "iopub.status.busy": "2025-03-26T18:00:49.142676Z",
     "iopub.status.idle": "2025-03-26T18:00:50.913999Z",
     "shell.execute_reply": "2025-03-26T18:00:50.913178Z",
     "shell.execute_reply.started": "2025-03-26T18:00:49.142954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>video_key</th>\n",
       "      <th>category</th>\n",
       "      <th>frame_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90382</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>walked past a woman in white</td>\n",
       "      <td>Normal_Videos_897_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90383</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>walked past a woman in white</td>\n",
       "      <td>Normal_Videos_897_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90384</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>walked past a woman in white</td>\n",
       "      <td>Normal_Videos_897_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90385</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>walked past a woman in white</td>\n",
       "      <td>Normal_Videos_897_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90386</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>walked past a woman in white</td>\n",
       "      <td>Normal_Videos_897_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90387 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_path  \\\n",
       "0      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "1      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "2      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "3      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "4      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "...                                                  ...   \n",
       "90382  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90383  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90384  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90385  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90386  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "\n",
       "                                                 caption  \\\n",
       "0      A woman with short hair, slightly fat, wearing...   \n",
       "1      A woman with short hair, slightly fat, wearing...   \n",
       "2      A woman with short hair, slightly fat, wearing...   \n",
       "3      A woman with short hair, slightly fat, wearing...   \n",
       "4      A woman with short hair, slightly fat, wearing...   \n",
       "...                                                  ...   \n",
       "90382                       walked past a woman in white   \n",
       "90383                       walked past a woman in white   \n",
       "90384                       walked past a woman in white   \n",
       "90385                       walked past a woman in white   \n",
       "90386                       walked past a woman in white   \n",
       "\n",
       "                    video_key category  frame_index  \n",
       "0               Abuse001_x264    Abuse            0  \n",
       "1               Abuse001_x264    Abuse           20  \n",
       "2               Abuse001_x264    Abuse           40  \n",
       "3               Abuse001_x264    Abuse           60  \n",
       "4               Abuse001_x264    Abuse           80  \n",
       "...                       ...      ...          ...  \n",
       "90382  Normal_Videos_897_x264   Normal          560  \n",
       "90383  Normal_Videos_897_x264   Normal          580  \n",
       "90384  Normal_Videos_897_x264   Normal          600  \n",
       "90385  Normal_Videos_897_x264   Normal          620  \n",
       "90386  Normal_Videos_897_x264   Normal          640  \n",
       "\n",
       "[90387 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# def process_large_csv(input_csv, output_csv=None, dataset_type=\"val\"):\n",
    "#     \"\"\"\n",
    "#     Reads a large CSV file, extracts required columns, modifies the image_path \n",
    "#     by removing dataset-specific prefixes and adding the correct directory,\n",
    "#     and optionally saves the processed DataFrame.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - input_csv (str): Path to the input CSV file.\n",
    "#     - output_csv (str, optional): Path to save the processed CSV file. If None, it won't save.\n",
    "#     - dataset_type (str): Type of dataset ('train', 'test', 'val') to determine path adjustments.\n",
    "    \n",
    "#     Returns:\n",
    "#     - pd.DataFrame: Processed DataFrame with updated image paths.\n",
    "#     \"\"\"\n",
    "#     #use_cols = [\"image_path\", \"caption\"]  # Load only needed columns\n",
    "\n",
    "#     # Read CSV with only required columns\n",
    "#     df = pd.read_csv(input_csv)\n",
    "\n",
    "#     # Define path mappings based on dataset type\n",
    "#     path_mappings = {\n",
    "#         \"train\": (\"output_frames/\", \"/kaggle/input/uca-ucf-dataset/train_ucf_output/\"),\n",
    "#         \"test\": (\"output_frames/\", \"/kaggle/input/uca-ucf-dataset/test_ucf_output/\"),\n",
    "#         \"val\": (\"val_output_frames/\", \"/kaggle/input/uca-ucf-dataset/Val_ucf_output/\")\n",
    "#     }\n",
    "\n",
    "#     # Get the correct replacement values\n",
    "#     remove_prefix, new_prefix = path_mappings.get(dataset_type, (\"\", \"\"))\n",
    "\n",
    "#     # Remove the dataset-specific prefix and add the correct directory\n",
    "#     df[\"image_path\"] = df[\"image_path\"].str.replace(remove_prefix, \"\", regex=False)\n",
    "#     df[\"image_path\"] = new_prefix + df[\"image_path\"]\n",
    "\n",
    "#     # Save the processed DataFrame if an output path is provided\n",
    "#     if output_csv:\n",
    "#         df.to_csv(output_csv, index=False)\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # Process train, test, and validation datasets with the correct path adjustments\n",
    "# train_df = process_large_csv(\"/kaggle/input/uca-ucf-dataset/train_image_captions (2).csv\", \n",
    "#                              \"train_ucf_set.csv\", dataset_type=\"train\")\n",
    "# test_df = process_large_csv(\"/kaggle/input/uca-ucf-dataset/test_image_captions.csv\", \n",
    "#                             \"test_ucf_set.csv\", dataset_type=\"test\")\n",
    "# valid_df = process_large_csv(\"/kaggle/input/uca-ucf-dataset/Val_image_captions.csv\", \n",
    "#                              \"valid_ucf_set.csv\", dataset_type=\"val\")\n",
    "\n",
    "# train_df  # Display first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Train, Test and Valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:59:46.277560Z",
     "iopub.status.busy": "2025-03-26T17:59:46.277193Z",
     "iopub.status.idle": "2025-03-26T17:59:46.292125Z",
     "shell.execute_reply": "2025-03-26T17:59:46.291436Z",
     "shell.execute_reply.started": "2025-03-26T17:59:46.277533Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image_path  \\\n",
      "0       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
      "1       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
      "2       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
      "3       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
      "4       /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
      "...                                                   ...   \n",
      "244198  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
      "244199  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
      "244200  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
      "244201  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
      "244202  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
      "\n",
      "                                                  caption  \\\n",
      "0       A woman with short hair, slightly fat, wearing...   \n",
      "1       A woman with short hair, slightly fat, wearing...   \n",
      "2       A woman with short hair, slightly fat, wearing...   \n",
      "3       A woman with short hair, slightly fat, wearing...   \n",
      "4       A woman with short hair, slightly fat, wearing...   \n",
      "...                                                   ...   \n",
      "244198  A woman wearing green half-sleeves on the left...   \n",
      "244199  A woman wearing green half-sleeves on the left...   \n",
      "244200  A woman wearing green half-sleeves on the left...   \n",
      "244201  A woman wearing green half-sleeves on the left...   \n",
      "244202  A woman wearing green half-sleeves on the left...   \n",
      "\n",
      "                    video_key category  frame_index  \n",
      "0               Abuse001_x264    Abuse            0  \n",
      "1               Abuse001_x264    Abuse           20  \n",
      "2               Abuse001_x264    Abuse           40  \n",
      "3               Abuse001_x264    Abuse           60  \n",
      "4               Abuse001_x264    Abuse           80  \n",
      "...                       ...      ...          ...  \n",
      "244198  Normal_Videos756_x264   Normal          460  \n",
      "244199  Normal_Videos756_x264   Normal          480  \n",
      "244200  Normal_Videos756_x264   Normal          500  \n",
      "244201  Normal_Videos756_x264   Normal          520  \n",
      "244202  Normal_Videos756_x264   Normal          540  \n",
      "\n",
      "[244203 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# ds1= pd.read_csv('/kaggle/input/ucf-small-dataset/train_image_captions.csv')\n",
    "# ds2= pd.read_csv('/kaggle/input/ucf-small-dataset/val_image_captions.csv')\n",
    "# ds3= pd.read_csv('/kaggle/input/ucf-small-dataset/test_image_captions.csv')\n",
    "\n",
    "combined_df = pd.concat([ds1, ds2, ds3], axis=0, ignore_index=True)\n",
    "print(combined_df)\n",
    "# # Now df contains the data from the CSV file\n",
    "# train_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:58:42.588413Z",
     "iopub.status.busy": "2025-03-26T17:58:42.588067Z",
     "iopub.status.idle": "2025-03-26T17:58:44.246941Z",
     "shell.execute_reply": "2025-03-26T17:58:44.246011Z",
     "shell.execute_reply.started": "2025-03-26T17:58:42.588386Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (83705, 5)\n",
      "Test set shape: (69554, 5)\n",
      "Validation set shape: (90944, 5)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# # Example: load your dataset\n",
    "# # Assuming your dataset is in a CSV file named 'dataset.csv'\n",
    "# df = combined_df\n",
    "\n",
    "# # Initialize empty DataFrames for each split\n",
    "# train_df = pd.DataFrame()\n",
    "# test_df = pd.DataFrame()\n",
    "# valid_df = pd.DataFrame()\n",
    "\n",
    "# # Define split percentages\n",
    "# train_pct = 0.3\n",
    "# # For the remaining 30%, you might split equally into test and valid (15% each)\n",
    "# # Alternatively, adjust as needed:\n",
    "# test_pct = 0.3\n",
    "# valid_pct = 0.3\n",
    "\n",
    "# # Process each category separately\n",
    "# for cat in df['category'].unique():\n",
    "#     cat_df = df[df['category'] == cat]\n",
    "#     # Get unique video_keys within this category\n",
    "#     video_keys = cat_df['video_key'].unique()\n",
    "#     # Shuffle video_keys for random split (set random_state for reproducibility)\n",
    "#     np.random.seed(42)\n",
    "#     np.random.shuffle(video_keys)\n",
    "    \n",
    "#     n_total = len(video_keys)\n",
    "#     n_train = int(train_pct * n_total)\n",
    "#     n_test = int(test_pct * n_total)\n",
    "#     # The remaining keys go to validation (or adjust if you want a different ratio)\n",
    "    \n",
    "#     train_keys = video_keys[:n_train]\n",
    "#     test_keys = video_keys[n_train:n_train+n_test]\n",
    "#     valid_keys = video_keys[n_train+n_test:]\n",
    "    \n",
    "#     # Assign all rows corresponding to these video_keys\n",
    "#     train_df = pd.concat([train_df, cat_df[cat_df['video_key'].isin(train_keys)]])\n",
    "#     test_df = pd.concat([test_df, cat_df[cat_df['video_key'].isin(test_keys)]])\n",
    "#     valid_df = pd.concat([valid_df, cat_df[cat_df['video_key'].isin(valid_keys)]])\n",
    "    \n",
    "# # Optionally, shuffle the final DataFrames\n",
    "# train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# valid_df = valid_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # Now train_df, test_df, and valid_df are your splits where each video_key remains intact.\n",
    "# print(\"Train set shape:\", train_df.shape)\n",
    "# print(\"Test set shape:\", test_df.shape)\n",
    "# print(\"Validation set shape:\", valid_df.shape)\n",
    "\n",
    "# # You can then save the splits to files if needed:\n",
    "# train_df.to_csv('train_split.csv', index=False)\n",
    "# test_df.to_csv('test_split.csv', index=False)\n",
    "# valid_df.to_csv('valid_split.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:50:22.113631Z",
     "iopub.status.busy": "2025-03-26T17:50:22.113407Z",
     "iopub.status.idle": "2025-03-26T17:50:22.463546Z",
     "shell.execute_reply": "2025-03-26T17:50:22.462698Z",
     "shell.execute_reply.started": "2025-03-26T17:50:22.113607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8357d5944e064e3096d9fe0bc5566f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:50:22.464901Z",
     "iopub.status.busy": "2025-03-26T17:50:22.464594Z",
     "iopub.status.idle": "2025-03-26T17:50:36.704780Z",
     "shell.execute_reply": "2025-03-26T17:50:36.703917Z",
     "shell.execute_reply.started": "2025-03-26T17:50:22.464870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.29.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->pycocotools) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->pycocotools) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->pycocotools) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->pycocotools) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->pycocotools) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->pycocotools) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install accelerate\n",
    "!pip install transformers\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:00:55.441589Z",
     "iopub.status.busy": "2025-03-26T18:00:55.441269Z",
     "iopub.status.idle": "2025-03-26T18:00:55.518123Z",
     "shell.execute_reply": "2025-03-26T18:00:55.517168Z",
     "shell.execute_reply.started": "2025-03-26T18:00:55.441562Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>video_key</th>\n",
       "      <th>category</th>\n",
       "      <th>frame_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>Three policemen came to the door, one walked i...</td>\n",
       "      <td>Abuse008_x264</td>\n",
       "      <td>Abuse</td>\n",
       "      <td>7420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>Many vehicles are driving on the road.</td>\n",
       "      <td>Arrest015_x264</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>Multiple firefighters were holding water pipe...</td>\n",
       "      <td>Explosion046_x264</td>\n",
       "      <td>Explosion</td>\n",
       "      <td>30220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>The big man kept slashing at his head and body.</td>\n",
       "      <td>Assault004_x264</td>\n",
       "      <td>Assault</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>Two men had a quarrel</td>\n",
       "      <td>Fighting010_x264</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90382</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>The woman in gray pulled away the man in the j...</td>\n",
       "      <td>Fighting004_x264</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90383</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>The camera changes the perspective, and the ma...</td>\n",
       "      <td>Robbery021_x264</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90384</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>The woman in the black and white skirt picked ...</td>\n",
       "      <td>Shoplifting014_x264</td>\n",
       "      <td>Shoplifting</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90385</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>The man walked around the sofa and came to a d...</td>\n",
       "      <td>Burglary040_x264</td>\n",
       "      <td>Burglary</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90386</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/train_ucf_output...</td>\n",
       "      <td>There were several people talking together in ...</td>\n",
       "      <td>Explosion046_x264</td>\n",
       "      <td>Explosion</td>\n",
       "      <td>73300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90387 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_path  \\\n",
       "0      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "1      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "2      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "3      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "4      /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "...                                                  ...   \n",
       "90382  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90383  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90384  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90385  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "90386  /kaggle/input/uca-ucf-dataset/train_ucf_output...   \n",
       "\n",
       "                                                 caption            video_key  \\\n",
       "0      Three policemen came to the door, one walked i...        Abuse008_x264   \n",
       "1                 Many vehicles are driving on the road.       Arrest015_x264   \n",
       "2       Multiple firefighters were holding water pipe...    Explosion046_x264   \n",
       "3        The big man kept slashing at his head and body.      Assault004_x264   \n",
       "4                                  Two men had a quarrel     Fighting010_x264   \n",
       "...                                                  ...                  ...   \n",
       "90382  The woman in gray pulled away the man in the j...     Fighting004_x264   \n",
       "90383  The camera changes the perspective, and the ma...      Robbery021_x264   \n",
       "90384  The woman in the black and white skirt picked ...  Shoplifting014_x264   \n",
       "90385  The man walked around the sofa and came to a d...     Burglary040_x264   \n",
       "90386  There were several people talking together in ...    Explosion046_x264   \n",
       "\n",
       "          category  frame_index  \n",
       "0            Abuse         7420  \n",
       "1           Arrest          480  \n",
       "2        Explosion        30220  \n",
       "3          Assault          840  \n",
       "4         Fighting         1740  \n",
       "...            ...          ...  \n",
       "90382     Fighting         7600  \n",
       "90383      Robbery          620  \n",
       "90384  Shoplifting        16100  \n",
       "90385     Burglary         2400  \n",
       "90386    Explosion        73300  \n",
       "\n",
       "[90387 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "valid_df = valid_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:37:29.147169Z",
     "iopub.status.busy": "2025-03-26T18:37:29.146882Z",
     "iopub.status.idle": "2025-03-26T18:37:29.157835Z",
     "shell.execute_reply": "2025-03-26T18:37:29.156964Z",
     "shell.execute_reply.started": "2025-03-26T18:37:29.147146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "      <th>video_key</th>\n",
       "      <th>category</th>\n",
       "      <th>frame_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/F...</td>\n",
       "      <td>Another man stood up to help pack things, and ...</td>\n",
       "      <td>Fighting050_x264</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>22560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/F...</td>\n",
       "      <td>Two people were arguing in the middle of the r...</td>\n",
       "      <td>Fighting048_x264</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>3580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/R...</td>\n",
       "      <td>The man reached for the money and then opened ...</td>\n",
       "      <td>Robbery143_x264</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n",
       "      <td>The bald man quickly walked away from the shel...</td>\n",
       "      <td>Normal_Videos689_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n",
       "      <td>A woman in a gray coat walked by, then turned ...</td>\n",
       "      <td>Normal_Videos676_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53043</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/F...</td>\n",
       "      <td>A man set up his bicycle for the man to ride a...</td>\n",
       "      <td>Fighting048_x264</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>5620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53044</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/S...</td>\n",
       "      <td>The silver car continued to move backwards</td>\n",
       "      <td>Stealing109_x264</td>\n",
       "      <td>Stealing</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53045</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n",
       "      <td>The man in the red hat chats with the man in blue</td>\n",
       "      <td>Normal_Videos689_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>11240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53046</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/R...</td>\n",
       "      <td>The two worked together to suppress and beat t...</td>\n",
       "      <td>Robbery127_x264</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53047</th>\n",
       "      <td>/kaggle/input/uca-ucf-dataset/Val_ucf_output/N...</td>\n",
       "      <td>A group of people enter the house</td>\n",
       "      <td>Normal_Videos681_x264</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53048 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_path  \\\n",
       "0      /kaggle/input/uca-ucf-dataset/Val_ucf_output/F...   \n",
       "1      /kaggle/input/uca-ucf-dataset/Val_ucf_output/F...   \n",
       "2      /kaggle/input/uca-ucf-dataset/Val_ucf_output/R...   \n",
       "3      /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
       "4      /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
       "...                                                  ...   \n",
       "53043  /kaggle/input/uca-ucf-dataset/Val_ucf_output/F...   \n",
       "53044  /kaggle/input/uca-ucf-dataset/Val_ucf_output/S...   \n",
       "53045  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
       "53046  /kaggle/input/uca-ucf-dataset/Val_ucf_output/R...   \n",
       "53047  /kaggle/input/uca-ucf-dataset/Val_ucf_output/N...   \n",
       "\n",
       "                                                 caption  \\\n",
       "0      Another man stood up to help pack things, and ...   \n",
       "1      Two people were arguing in the middle of the r...   \n",
       "2      The man reached for the money and then opened ...   \n",
       "3      The bald man quickly walked away from the shel...   \n",
       "4      A woman in a gray coat walked by, then turned ...   \n",
       "...                                                  ...   \n",
       "53043  A man set up his bicycle for the man to ride a...   \n",
       "53044         The silver car continued to move backwards   \n",
       "53045  The man in the red hat chats with the man in blue   \n",
       "53046  The two worked together to suppress and beat t...   \n",
       "53047                  A group of people enter the house   \n",
       "\n",
       "                   video_key  category  frame_index  \n",
       "0           Fighting050_x264  Fighting        22560  \n",
       "1           Fighting048_x264  Fighting         3580  \n",
       "2            Robbery143_x264   Robbery          700  \n",
       "3      Normal_Videos689_x264    Normal         8320  \n",
       "4      Normal_Videos676_x264    Normal         2660  \n",
       "...                      ...       ...          ...  \n",
       "53043       Fighting048_x264  Fighting         5620  \n",
       "53044       Stealing109_x264  Stealing         1080  \n",
       "53045  Normal_Videos689_x264    Normal        11240  \n",
       "53046        Robbery127_x264   Robbery          500  \n",
       "53047  Normal_Videos681_x264    Normal         9280  \n",
       "\n",
       "[53048 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:01:24.538965Z",
     "iopub.status.busy": "2025-03-26T18:01:24.538668Z",
     "iopub.status.idle": "2025-03-26T18:01:25.770314Z",
     "shell.execute_reply": "2025-03-26T18:01:25.769358Z",
     "shell.execute_reply.started": "2025-03-26T18:01:24.538943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named ds\n",
    "train_df.to_csv('Train_ds.csv', index=False)\n",
    "valid_df.to_csv('Valid_ds.csv', index=False)\n",
    "test_df.to_csv('Test_ds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:50:37.985173Z",
     "iopub.status.busy": "2025-03-26T17:50:37.984929Z",
     "iopub.status.idle": "2025-03-26T17:50:37.988102Z",
     "shell.execute_reply": "2025-03-26T17:50:37.987423Z",
     "shell.execute_reply.started": "2025-03-26T17:50:37.985153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Read the CSV file into a DataFrame\n",
    "# train_df = pd.read_csv('/kaggle/input/uca-ucf-dataset/Train_ds (3).csv')\n",
    "# valid_df= pd.read_csv('/kaggle/input/uca-ucf-dataset/Valid_ds (3).csv')\n",
    "# test_df = pd.read_csv('/kaggle/input/uca-ucf-dataset/Test_ds (3).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:37:53.638153Z",
     "iopub.status.busy": "2025-03-26T18:37:53.637858Z",
     "iopub.status.idle": "2025-03-26T18:37:54.010556Z",
     "shell.execute_reply": "2025-03-26T18:37:54.009843Z",
     "shell.execute_reply.started": "2025-03-26T18:37:53.638131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image_path', 'caption', 'video_key', 'category', 'frame_index'],\n",
       "        num_rows: 90387\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image_path', 'caption', 'video_key', 'category', 'frame_index'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image_path', 'caption', 'video_key', 'category', 'frame_index'],\n",
       "        num_rows: 100768\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Convert each split into a Dataset object\n",
    "train_datads = Dataset.from_pandas(train_df)\n",
    "valid_datads = Dataset.from_pandas(valid_df[:10000])\n",
    "test_datads = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Organize the splits into a DatasetDict\n",
    "ds = DatasetDict({\n",
    "    \"train\": train_datads,\n",
    "    \"validation\": valid_datads,\n",
    "    \"test\": test_datads\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize VisionEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:50:39.743633Z",
     "iopub.status.busy": "2025-03-26T17:50:39.743038Z",
     "iopub.status.idle": "2025-03-26T17:51:44.603101Z",
     "shell.execute_reply": "2025-03-26T17:51:44.602176Z",
     "shell.execute_reply.started": "2025-03-26T17:50:39.743600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6f3b1993d24660b449c171976393dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf7562ba3be4af9815df7e9354cd141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/957M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.47.0\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'> is overwritten by shared decoder config: GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.47.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fa162e50b543f28eb5b077b6863746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/149 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d117dbb4bb4e168358524310719649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5684275577447c939ccde5c9a888ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fa3546fc6843f4945a1a6998d9eea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f222b7fc7cf44a89347c1675ebf7530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4d02e774404b8aa1ecd30711411326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a52bbac53f4c02872ace702bcfddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('vit-gpt2-model/tokenizer_config.json',\n",
       " 'vit-gpt2-model/special_tokens_map.json',\n",
       " 'vit-gpt2-model/vocab.json',\n",
       " 'vit-gpt2-model/merges.txt',\n",
       " 'vit-gpt2-model/added_tokens.json',\n",
       " 'vit-gpt2-model/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor\n",
    "from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor, ViTImageProcessor\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Initialize tokenizer and feature extractor (replace 'model_name' with your model's name)\n",
    "#tokenizer = AutoTokenizer.from_pretrained('model_name')\n",
    "#feature_extractor = AutoFeatureExtractor.from_pretrained('model_name')\n",
    "model_name=\"NourFakih/Vit-GPT2-COCO2017Flickr-85k-09\"\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# GPT2 only has bos/eos tokens but not decoder_start/pad tokens\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# update the model config\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "output_dir = \"vit-gpt2-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB_DISABLED and nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:51:44.604841Z",
     "iopub.status.busy": "2025-03-26T17:51:44.604069Z",
     "iopub.status.idle": "2025-03-26T17:51:45.579444Z",
     "shell.execute_reply": "2025-03-26T17:51:45.578550Z",
     "shell.execute_reply.started": "2025-03-26T17:51:44.604808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "from transformers import VisionEncoderDecoderModel, AutoFeatureExtractor,AutoTokenizer\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except (LookupError, OSError):\n",
    "    nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:51:45.580621Z",
     "iopub.status.busy": "2025-03-26T17:51:45.580375Z",
     "iopub.status.idle": "2025-03-26T17:51:57.194726Z",
     "shell.execute_reply": "2025-03-26T17:51:57.193615Z",
     "shell.execute_reply.started": "2025-03-26T17:51:45.580601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=386ed069b17a4a2a57ea84ddb832051d824c30c1b633449b91daa6a9d34f44bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:51:57.196177Z",
     "iopub.status.busy": "2025-03-26T17:51:57.195911Z",
     "iopub.status.idle": "2025-03-26T17:51:59.118252Z",
     "shell.execute_reply": "2025-03-26T17:51:59.117637Z",
     "shell.execute_reply.started": "2025-03-26T17:51:57.196151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5559f7faa01a408aa7e99860261b774a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ignore_pad_token_for_loss = True\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T17:51:59.119441Z",
     "iopub.status.busy": "2025-03-26T17:51:59.119118Z",
     "iopub.status.idle": "2025-03-26T17:51:59.125296Z",
     "shell.execute_reply": "2025-03-26T17:51:59.124378Z",
     "shell.execute_reply.started": "2025-03-26T17:51:59.119410Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # Ensure preds is a NumPy array\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.cpu().numpy()\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    # Debugging\n",
    "    print(\"Preds before decoding:\", preds)\n",
    "    \n",
    "    # Ensure valid token IDs\n",
    "    preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    if ignore_pad_token_for_loss:\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:01:34.848060Z",
     "iopub.status.busy": "2025-03-26T18:01:34.847730Z",
     "iopub.status.idle": "2025-03-26T18:01:34.855099Z",
     "shell.execute_reply": "2025-03-26T18:01:34.854118Z",
     "shell.execute_reply.started": "2025-03-26T18:01:34.848033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "# Fix attention mask issue by explicitly setting pad token\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Set pad_token to eos_token to prevent warnings\n",
    "\n",
    "\n",
    "class ImageCapatioingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds, ds_type, max_target_length):\n",
    "        self.ds = ds\n",
    "        self.max_target_length = max_target_length\n",
    "        self.ds_type = ds_type\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.ds[self.ds_type]['image_path'][idx]\n",
    "        caption = self.ds[self.ds_type]['caption'][idx]\n",
    "        model_inputs = dict()\n",
    "        model_inputs['labels'] = self.tokenization_fn(caption, self.max_target_length)\n",
    "        model_inputs['pixel_values'] = self.feature_extraction_fn(image_path)\n",
    "        return model_inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds[self.ds_type])\n",
    "    \n",
    "    # text preprocessing step\n",
    "    def tokenization_fn(self, caption, max_target_length):\n",
    "        \"\"\"Run tokenization on caption.\"\"\"\n",
    "        labels = tokenizer(caption, \n",
    "                          padding=\"max_length\", \n",
    "                          max_length=max_target_length).input_ids\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    # image preprocessing step\n",
    "    def feature_extraction_fn(self, image_path):\n",
    "        \"\"\"\n",
    "        Run feature extraction on images\n",
    "        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n",
    "        Otherwise, an exception will be thrown.\n",
    "        \"\"\"\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = image.resize((224, 224))\n",
    "\n",
    "        encoder_inputs = feature_extractor(images=image, return_tensors=\"np\")\n",
    "\n",
    "        return encoder_inputs.pixel_values[0]\n",
    "\n",
    "\n",
    "train_ds = ImageCapatioingDataset(ds, 'train', 256)\n",
    "eval_ds = ImageCapatioingDataset(ds, 'validation', 256)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T18:38:14.646456Z",
     "iopub.status.busy": "2025-03-26T18:38:14.646143Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "<ipython-input-34-8191b409b71b>:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='16947' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   43/16947 02:38 < 18:08:33, 0.26 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "output_dir=\"./Vit-GPT2-UCA-UCF-06\"\n",
    "hub_model_id=\"NourFakih/Vit-GPT2-UCA-UCF-06\"\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    #evaluation_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    #tpu_num_cores\n",
    "    #accelerator_config (str, dict, or AcceleratorConfig, optional),\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"all_checkpoints\",\n",
    "    #resume_from_checkpoint=\"./Vit-GPT2-UCA-UCF-05/checkpoint-500\",\n",
    "    hub_always_push=True,\n",
    "    hub_model_id=hub_model_id\n",
    ")\n",
    "from transformers import default_data_collator\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T17:52:01.894254Z",
     "iopub.status.idle": "2025-03-26T17:52:01.894655Z",
     "shell.execute_reply": "2025-03-26T17:52:01.894477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T17:52:01.895390Z",
     "iopub.status.idle": "2025-03-26T17:52:01.895771Z",
     "shell.execute_reply": "2025-03-26T17:52:01.895605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T17:52:01.896768Z",
     "iopub.status.idle": "2025-03-26T17:52:01.897096Z",
     "shell.execute_reply": "2025-03-26T17:52:01.896965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T17:52:01.897837Z",
     "iopub.status.idle": "2025-03-26T17:52:01.898076Z",
     "shell.execute_reply": "2025-03-26T17:52:01.897977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_extractor.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T17:52:01.899029Z",
     "iopub.status.idle": "2025-03-26T17:52:01.899432Z",
     "shell.execute_reply": "2025-03-26T17:52:01.899256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_extractor.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T17:52:01.900140Z",
     "iopub.status.idle": "2025-03-26T17:52:01.900421Z",
     "shell.execute_reply": "2025-03-26T17:52:01.900314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T17:52:01.901353Z",
     "iopub.status.idle": "2025-03-26T17:52:01.901688Z",
     "shell.execute_reply": "2025-03-26T17:52:01.901525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(hub_model_id)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6958923,
     "sourceId": 11153574,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6945353,
     "sourceId": 11173133,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7220397,
     "sourceId": 11514066,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
