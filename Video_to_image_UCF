{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9426131,"sourceType":"datasetVersion","datasetId":5725956},{"sourceId":11049637,"sourceType":"datasetVersion","datasetId":6883624},{"sourceId":11090211,"sourceType":"datasetVersion","datasetId":6912911},{"sourceId":11153574,"sourceType":"datasetVersion","datasetId":6958923}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Notebook Summary**\n\nThis notebook processes the UCF-Crime dataset by extracting frames from videos and pairing them with their corresponding caption annotations based on time intervals. It supports multiple splitting strategies for train, validation, and test sets, including regular frame sampling and scene-based key frame extraction using PySceneDetect. For each video, frames are sampled at fixed intervals or scene boundaries, matched to timestamped captions, and saved to disk alongside metadata such as video category and frame index. The results are compiled into CSV files for later use in image-captioning models. The notebook also includes a utility to sample and organize videos by category, generate new annotation files, and export processed data as ZIP archives for download or deployment.","metadata":{}},{"cell_type":"markdown","source":"## Extract Frames From 100 Videos max for each category and Save them each in their corresponding video folder","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport re\nimport pandas as pd\nfrom collections import defaultdict\n\n# Paths for annotations, videos, output frames, and CSV file\nANNOTATIONS_FILE = '/kaggle/input/ucaucf-crime-annotation-dataset/UCFCrime_Test.json'\nVIDEOS_DIR = '/kaggle/input/ucaucf-crime-annotation-dataset/UCF_Crimes/UCF_Crimes/Videos'    # e.g., \"./UCF_Crimes/Videos/\"\nOUTPUT_DIR = 'output_frames'           # Folder to save the extracted frames\nCSV_FILE = 'image_captions.csv'        # CSV file to save image path and caption pairs\n\n# List of possible file extensions in your dataset\nVIDEO_EXTENSIONS = ['.mp4', '.avi', '.mov', '.mkv']\n\n# Maximum number of videos to process per category\nMAX_PER_CATEGORY = 100\n\ndef find_video_file(video_name, base_dir, exts):\n    \"\"\"\n    Search recursively under `base_dir` for a file that has the same\n    (base) name as `video_name` and one of the allowed `exts`.\n    Returns the full path if found, else None.\n    \"\"\"\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            name, ext = os.path.splitext(file)\n            if name == video_name and ext.lower() in exts:\n                return os.path.join(root, file)\n    return None\n\ndef extract_category_from_key(video_key):\n    \"\"\"\n    Extract the category name from the start of the video key.\n    For example, 'Abuse001_x264' -> 'Abuse'\n    Adjust this logic if your naming convention is different.\n    \"\"\"\n    match = re.match(r'([A-Za-z]+)', video_key)\n    if match:\n        return match.group(1)\n    return \"Unknown\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Load the JSON annotations\nwith open(ANNOTATIONS_FILE, 'r') as f:\n    annotations = json.load(f)\n\n# Keep track of how many videos processed per category\ncategory_count = defaultdict(int)\n\n# List to collect dictionaries with image paths and captions\ndata_entries = []\n\n# Iterate over each video entry in the JSON\nfor video_name, data in annotations.items():\n    # Identify the category from the video key\n    category = extract_category_from_key(video_name)\n\n    # If we already have 100 videos for this category, skip\n    if category_count[category] >= MAX_PER_CATEGORY:\n        continue\n\n    # Attempt to find the actual video file in subfolders\n    video_file = find_video_file(video_name, VIDEOS_DIR, VIDEO_EXTENSIONS)\n    if not video_file:\n        print(f\"[WARNING] Could not find file for video key '{video_name}'\")\n        continue\n\n    # Try to open the video\n    cap = cv2.VideoCapture(video_file)\n    if not cap.isOpened():\n        print(f\"[ERROR] Unable to open video file: {video_file}\")\n        continue\n\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    print(f\"Processing '{video_name}' in category '{category}' at {fps} fps.\")\n\n    # Create a subdirectory for frames from this video\n    video_out_dir = os.path.join(OUTPUT_DIR, video_name)\n    os.makedirs(video_out_dir, exist_ok=True)\n\n    # Get timestamps and sentences lists\n    timestamps = data.get(\"timestamps\", [])\n    sentences = data.get(\"sentences\", [])\n\n    frame_index = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break  # End of video\n\n        # Sample every 20th frame (modify this value as needed)\n        if frame_index % 20 == 0:\n            current_time = frame_index / fps\n            caption = None\n\n            # Determine which timestamp interval covers the current frame time\n            for idx, interval in enumerate(timestamps):\n                start, end = interval\n                if start <= current_time <= end:\n                    caption = sentences[idx]\n                    break\n\n            # If a caption is found, save the frame and record the data\n            if caption is not None:\n                image_filename = f\"{video_name}_frame{frame_index}.jpg\"\n                image_path = os.path.join(video_out_dir, image_filename)\n                cv2.imwrite(image_path, frame)\n\n                data_entries.append({\n                    'image_path': image_path,\n                    'caption': caption,\n                    'video_key': video_name,\n                    'category': category,\n                    'frame_index': frame_index\n                })\n                #print(f\"Saved: {image_path}, Caption: {caption}\")\n\n        frame_index += 1\n\n    cap.release()\n\n    # Increase the count for this category\n    category_count[category] += 1\n\n    # If we've now reached the max for this category, print a message\n    if category_count[category] == MAX_PER_CATEGORY:\n        print(f\"[INFO] Reached {MAX_PER_CATEGORY} videos in category '{category}'.\")\n\n# Convert the collected data into a DataFrame and save as a CSV file\ndf = pd.DataFrame(data_entries)\ndf.to_csv(CSV_FILE, index=False)\nprint(f\"Data saved to {CSV_FILE}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T15:10:42.278938Z","iopub.execute_input":"2025-03-20T15:10:42.279312Z","iopub.status.idle":"2025-03-20T15:30:00.807923Z","shell.execute_reply.started":"2025-03-20T15:10:42.279274Z","shell.execute_reply":"2025-03-20T15:30:00.805851Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Extract Frames From 110 Videos max for each category","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport re\nimport pandas as pd\nfrom collections import defaultdict\n\n# Paths for annotations, videos, output frames, and CSV file\nANNOTATIONS_FILE = '/kaggle/input/ucaucf-crime-annotation-dataset/UCFCrime_Val.json'\nVIDEOS_DIR = '/kaggle/input/ucaucf-crime-annotation-dataset/UCF_Crimes/UCF_Crimes/Videos'    # e.g., \"./UCF_Crimes/Videos/\"\nOUTPUT_DIR = 'val_output_frames'           # All images will now be saved in one folder\nCSV_FILE = 'Val_image_captions.csv'        # CSV file to save image path and caption pairs\n\n# List of possible file extensions in your dataset\nVIDEO_EXTENSIONS = ['.mp4', '.avi', '.mov', '.mkv']\n\n# Maximum number of videos to process per category\nMAX_PER_CATEGORY = 110\n\ndef find_video_file(video_name, base_dir, exts):\n    \"\"\"\n    Search recursively under `base_dir` for a file that has the same\n    (base) name as `video_name` and one of the allowed `exts`.\n    Returns the full path if found, else None.\n    \"\"\"\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            name, ext = os.path.splitext(file)\n            if name == video_name and ext.lower() in exts:\n                return os.path.join(root, file)\n    return None\n\ndef extract_category_from_key(video_key):\n    \"\"\"\n    Extract the category name from the start of the video key.\n    For example, 'Abuse001_x264' -> 'Abuse'\n    Adjust this logic if your naming convention is different.\n    \"\"\"\n    match = re.match(r'([A-Za-z]+)', video_key)\n    if match:\n        return match.group(1)\n    return \"Unknown\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Load the JSON annotations\nwith open(ANNOTATIONS_FILE, 'r') as f:\n    annotations = json.load(f)\n\n# Keep track of how many videos processed per category\ncategory_count = defaultdict(int)\n\n# List to collect dictionaries with image paths and captions\ndata_entries = []\n\n# Iterate over each video entry in the JSON\nfor video_name, data in annotations.items():\n    # Identify the category from the video key\n    category = extract_category_from_key(video_name)\n\n    # If we already have 100 videos for this category, skip\n    if category_count[category] >= MAX_PER_CATEGORY:\n        continue\n\n    # Attempt to find the actual video file in subfolders\n    video_file = find_video_file(video_name, VIDEOS_DIR, VIDEO_EXTENSIONS)\n    if not video_file:\n        print(f\"[WARNING] Could not find file for video key '{video_name}'\")\n        continue\n\n    # Try to open the video\n    cap = cv2.VideoCapture(video_file)\n    if not cap.isOpened():\n        print(f\"[ERROR] Unable to open video file: {video_file}\")\n        continue\n\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    print(f\"Processing '{video_name}' in category '{category}' at {fps} fps.\")\n\n    # Get timestamps and sentences lists\n    timestamps = data.get(\"timestamps\", [])\n    sentences = data.get(\"sentences\", [])\n\n    frame_index = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break  # End of video\n\n        # Sample every 20th frame (modify this value as needed)\n        if frame_index % 20 == 0:\n            current_time = frame_index / fps\n            caption = None\n\n            # Determine which timestamp interval covers the current frame time\n            for idx, interval in enumerate(timestamps):\n                start, end = interval\n                if start <= current_time <= end:\n                    caption = sentences[idx]\n                    break\n\n            # If a caption is found, save the frame and record the data\n            if caption is not None:\n                image_filename = f\"{video_name}_frame{frame_index}.jpg\"\n                image_path = os.path.join(OUTPUT_DIR, image_filename)\n                cv2.imwrite(image_path, frame)\n\n                data_entries.append({\n                    'image_path': image_path,\n                    'caption': caption,\n                    'video_key': video_name,\n                    'category': category,\n                    'frame_index': frame_index\n                })\n                #print(f\"Saved: {image_path}, Caption: {caption}\")\n\n        frame_index += 1\n\n    cap.release()\n\n    # Increase the count for this category\n    category_count[category] += 1\n\n    # If we've now reached the max for this category, print a message\n    if category_count[category] == MAX_PER_CATEGORY:\n        print(f\"[INFO] Reached {MAX_PER_CATEGORY} videos in category '{category}'.\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T09:47:30.269119Z","iopub.execute_input":"2025-03-23T09:47:30.269823Z","iopub.status.idle":"2025-03-23T09:55:58.742722Z","shell.execute_reply.started":"2025-03-23T09:47:30.269757Z","shell.execute_reply":"2025-03-23T09:55:58.741583Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Process with PySceneDetect to get key frames","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport re\nimport pandas as pd\nfrom collections import defaultdict\n\n# 1) Import PySceneDetect\n!pip install scenedetect --quiet\nfrom scenedetect import VideoManager, SceneManager\nfrom scenedetect.detectors import ContentDetector\nfrom scenedetect.scene_manager import StatsManager\n\n# Paths for annotations, videos, output frames, and CSV file\nANNOTATIONS_FILE = '/kaggle/input/ucaucf-crime-annotation-dataset/UCFCrime_Val.json'\nVIDEOS_DIR = '/kaggle/input/ucaucf-crime-annotation-dataset/UCF_Crimes/UCF_Crimes/Videos'  # Adjust if needed\nOUTPUT_DIR = 'val_output_frames'          # All images saved in one folder\nCSV_FILE = 'Val_image_captions.csv'       # CSV file to save image path & caption pairs\n\n# List of possible file extensions in your dataset\nVIDEO_EXTENSIONS = ['.mp4', '.avi', '.mov', '.mkv']\n\n# Max number of videos to process per category\nMAX_PER_CATEGORY = 110\n\ndef find_video_file(video_name, base_dir, exts):\n    \"\"\"\n    Search recursively under `base_dir` for a file that has the same\n    (base) name as `video_name` and one of the allowed `exts`.\n    Returns the full path if found, else None.\n    \"\"\"\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            name, ext = os.path.splitext(file)\n            if name == video_name and ext.lower() in exts:\n                return os.path.join(root, file)\n    return None\n\ndef extract_category_from_key(video_key):\n    \"\"\"\n    Extract the category name from the start of the video key.\n    E.g., 'Abuse001_x264' -> 'Abuse'.\n    Adjust logic if your naming convention differs.\n    \"\"\"\n    match = re.match(r'([A-Za-z]+)', video_key)\n    if match:\n        return match.group(1)\n    return \"Unknown\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Load the JSON annotations\nwith open(ANNOTATIONS_FILE, 'r') as f:\n    annotations = json.load(f)\n\n# Track how many videos processed per category\ncategory_count = defaultdict(int)\n\n# List to collect dictionaries with image paths and captions\ndata_entries = []\n\n# 2) Function to detect scenes and pick key frames\ndef detect_scenes_and_extract_frames(video_path, video_name, category, timestamps, sentences):\n    \"\"\"\n    Use PySceneDetect to detect scene boundaries and then extract a representative frame\n    from each scene. For each key frame, find which caption it belongs to (using timestamps).\n    \"\"\"\n    # --- Setup PySceneDetect ---\n    video_manager = VideoManager([video_path])\n    stats_manager = StatsManager()\n    scene_manager = SceneManager(stats_manager)\n    \n    # ContentDetector: you can tune the threshold to get more/fewer scenes\n    scene_manager.add_detector(ContentDetector(threshold=30.0))\n    \n    # Start the video manager & perform scene detection\n    video_manager.start()\n    scene_manager.detect_scenes(frame_source=video_manager)\n    scene_list = scene_manager.get_scene_list()\n    \n    # Re-open video with OpenCV for frame extraction\n    cap = cv2.VideoCapture(video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    \n    frames_and_captions = []  # store (frame_index, caption) pairs\n\n    # 3) For each scene, pick a representative frame\n    for i, scene in enumerate(scene_list):\n        start_tc, end_tc = scene\n        start_frame = start_tc.get_frames()\n        end_frame = end_tc.get_frames()\n        \n        # Pick the midpoint frame of the scene\n        mid_frame = (start_frame + end_frame) // 2\n        cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame)\n        ret, frame = cap.read()\n        if not ret:\n            continue\n        \n        # Find the time (in seconds) for the mid frame\n        mid_time_sec = mid_frame / fps\n        \n        # Match to the correct caption based on timestamps\n        matched_caption = None\n        for idx, interval in enumerate(timestamps):\n            start, end = interval\n            if start <= mid_time_sec <= end:\n                matched_caption = sentences[idx]\n                break\n        \n        if matched_caption:\n            image_filename = f\"{video_name}_frame{mid_frame}.jpg\"\n            image_path = os.path.join(OUTPUT_DIR, image_filename)\n            cv2.imwrite(image_path, frame)\n            \n            frames_and_captions.append({\n                'image_path': image_path,\n                'caption': matched_caption,\n                'video_key': video_name,\n                'category': category,\n                'frame_index': mid_frame\n            })\n    \n    cap.release()\n    video_manager.release()\n    return frames_and_captions\n\n# 4) Main loop: process each video using scene detection\nfor video_name, data in annotations.items():\n    # Identify the category from the video key\n    category = extract_category_from_key(video_name)\n\n    # If we already have enough videos for this category, skip\n    if category_count[category] >= MAX_PER_CATEGORY:\n        continue\n\n    # Find the actual video file\n    video_file = find_video_file(video_name, VIDEOS_DIR, VIDEO_EXTENSIONS)\n    if not video_file:\n        print(f\"[WARNING] Could not find file for video key '{video_name}'\")\n        continue\n\n    # Extract timestamps and sentences\n    timestamps = data.get(\"timestamps\", [])  # list of (start, end) in seconds\n    sentences = data.get(\"sentences\", [])    # list of caption strings\n\n    print(f\"Processing '{video_name}' in category '{category}'...\")\n\n    # Use PySceneDetect to get key frames\n    frames_captions = detect_scenes_and_extract_frames(\n        video_path=video_file,\n        video_name=video_name,\n        category=category,\n        timestamps=timestamps,\n        sentences=sentences\n    )\n\n    # Append results\n    data_entries.extend(frames_captions)\n\n    # Increase the count for this category\n    category_count[category] += 1\n    if category_count[category] == MAX_PER_CATEGORY:\n        print(f\"[INFO] Reached {MAX_PER_CATEGORY} videos in category '{category}'.\")\n\n# 5) Convert to DataFrame and save to CSV\ndf = pd.DataFrame(data_entries)\ndf.to_csv(CSV_FILE, index=False)\nprint(f\"\\n[INFO] Saved {len(df)} extracted frames to '{CSV_FILE}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T12:50:01.990569Z","iopub.execute_input":"2025-03-24T12:50:01.991255Z","iopub.status.idle":"2025-03-24T12:59:41.936192Z","shell.execute_reply.started":"2025-03-24T12:50:01.99094Z","shell.execute_reply":"2025-03-24T12:59:41.934023Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport re\nimport pandas as pd\nfrom collections import defaultdict\n\n# 1) Install & Import PySceneDetect\n!pip install scenedetect --quiet\nfrom scenedetect import VideoManager, SceneManager\nfrom scenedetect.detectors import ContentDetector\nfrom scenedetect.scene_manager import StatsManager\n\n# Paths for annotations, videos, output frames, and CSV file\nANNOTATIONS_FILE = '/kaggle/input/ucaucf-crime-annotation-dataset/UCFCrime_Test.json'\nVIDEOS_DIR = '/kaggle/input/ucaucf-crime-annotation-dataset/UCF_Crimes/UCF_Crimes/Videos'\nOUTPUT_DIR = 'test_output_frames'\nCSV_FILE = 'test_image_captions.csv'\n\n# Allowed video file extensions\nVIDEO_EXTENSIONS = ['.mp4', '.avi', '.mov', '.mkv']\n\n# Max videos per category\nMAX_PER_CATEGORY = 150\n\ndef find_video_file(video_name, base_dir, exts):\n    \"\"\"\n    Search recursively under `base_dir` for a file that has the same\n    (base) name as `video_name` and one of the allowed `exts`.\n    Returns the full path if found, else None.\n    \"\"\"\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            name, ext = os.path.splitext(file)\n            if name == video_name and ext.lower() in exts:\n                return os.path.join(root, file)\n    return None\n\ndef extract_category_from_key(video_key):\n    \"\"\"\n    Extract the category name from the start of the video key.\n    e.g., 'Abuse001_x264' -> 'Abuse'.\n    \"\"\"\n    match = re.match(r'([A-Za-z]+)', video_key)\n    if match:\n        return match.group(1)\n    return \"Unknown\"\n\n# Create output directory\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Load JSON annotations\nwith open(ANNOTATIONS_FILE, 'r') as f:\n    annotations = json.load(f)\n\ncategory_count = defaultdict(int)\ndata_entries = []\n\ndef detect_scenes_and_extract_frames(\n    video_path, video_name, category,\n    timestamps, sentences,\n    frames_per_scene=3  # <--- We want multiple frames per scene\n):\n    \"\"\"\n    Use PySceneDetect to detect scene boundaries and extract multiple frames \n    from each scene. For each frame, we find the matching caption based on timestamps.\n    \"\"\"\n    # --- Setup PySceneDetect ---\n    video_manager = VideoManager([video_path])\n    stats_manager = StatsManager()\n    scene_manager = SceneManager(stats_manager)\n    \n    # Adjust threshold to tune sensitivity\n    scene_manager.add_detector(ContentDetector(threshold=30.0))\n    \n    # Start the video manager & perform scene detection\n    video_manager.start()\n    scene_manager.detect_scenes(frame_source=video_manager)\n    scene_list = scene_manager.get_scene_list()\n    \n    # Re-open video with OpenCV for frame extraction\n    cap = cv2.VideoCapture(video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    \n    frames_and_captions = []\n    \n    # For each scene, extract multiple frames\n    for scene_idx, scene in enumerate(scene_list):\n        start_tc, end_tc = scene\n        start_frame = start_tc.get_frames()\n        end_frame = end_tc.get_frames()\n        scene_length = end_frame - start_frame\n        \n        # If scene is too short, just skip or pick 1 frame\n        if scene_length <= 0:\n            continue\n        \n        # Example: evenly space frames_per_scene frames across the scene\n        for i in range(frames_per_scene):\n            fraction = i / (frames_per_scene - 1) if frames_per_scene > 1 else 0\n            frame_idx = start_frame + int(scene_length * fraction)\n            \n            # Set video position & read the frame\n            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n            ret, frame = cap.read()\n            if not ret:\n                continue\n            \n            # Current time in seconds\n            current_time_sec = frame_idx / fps\n            \n            # Find matching caption\n            matched_caption = None\n            for idx, interval in enumerate(timestamps):\n                start_sec, end_sec = interval\n                if start_sec <= current_time_sec <= end_sec:\n                    matched_caption = sentences[idx]\n                    break\n            \n            if matched_caption:\n                image_filename = f\"{video_name}_scene{scene_idx}_frame{frame_idx}.jpg\"\n                image_path = os.path.join(OUTPUT_DIR, image_filename)\n                cv2.imwrite(image_path, frame)\n                \n                frames_and_captions.append({\n                    'image_path': image_path,\n                    'caption': matched_caption,\n                    'video_key': video_name,\n                    'category': category,\n                    'frame_index': frame_idx\n                })\n    \n    cap.release()\n    video_manager.release()\n    return frames_and_captions\n\n# Main loop\nfor video_name, data in annotations.items():\n    category = extract_category_from_key(video_name)\n\n    if category_count[category] >= MAX_PER_CATEGORY:\n        continue\n\n    video_file = find_video_file(video_name, VIDEOS_DIR, VIDEO_EXTENSIONS)\n    if not video_file:\n        print(f\"[WARNING] Could not find file for video key '{video_name}'\")\n        continue\n\n    timestamps = data.get(\"timestamps\", [])\n    sentences = data.get(\"sentences\", [])\n\n    print(f\"Processing '{video_name}' in category '{category}'...\")\n\n    frames_captions = detect_scenes_and_extract_frames(\n        video_path=video_file,\n        video_name=video_name,\n        category=category,\n        timestamps=timestamps,\n        sentences=sentences,\n        frames_per_scene=3  # <--- Change this to however many frames you want per scene\n    )\n\n    data_entries.extend(frames_captions)\n    category_count[category] += 1\n    \n    if category_count[category] == MAX_PER_CATEGORY:\n        print(f\"[INFO] Reached {MAX_PER_CATEGORY} videos in category '{category}'.\")\n\n# Convert to DataFrame and save\ndf = pd.DataFrame(data_entries)\ndf.to_csv(CSV_FILE, index=False)\nprint(f\"[INFO] Saved {len(df)} extracted frames to '{CSV_FILE}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:47:19.012035Z","iopub.execute_input":"2025-03-24T18:47:19.012548Z","iopub.status.idle":"2025-03-24T20:24:27.001719Z","shell.execute_reply.started":"2025-03-24T18:47:19.012511Z","shell.execute_reply":"2025-03-24T20:24:26.999143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Extract Frames From all Videos and save them in 1 Folder","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport re\nimport pandas as pd\nfrom collections import defaultdict\n\n# Paths for annotations, videos, output frames, and CSV file\nANNOTATIONS_FILE = '/kaggle/input/ucaucf-crime-annotation-dataset/UCFCrime_Train.json'\nVIDEOS_DIR = '/kaggle/input/ucaucf-crime-annotation-dataset/UCF_Crimes/UCF_Crimes/Videos'    # e.g., \"./UCF_Crimes/Videos/\"\nOUTPUT_DIR = 'output-frames'           # All images will be saved in one folder\nCSV_FILE = 'train_image_captions.csv'    # CSV file to save image path and caption pairs\n\n# List of possible file extensions in your dataset\nVIDEO_EXTENSIONS = ['.mp4', '.avi', '.mov', '.mkv']\n\ndef find_video_file(video_name, base_dir, exts):\n    \"\"\"\n    Search recursively under `base_dir` for a file that has the same\n    (base) name as `video_name` and one of the allowed `exts`.\n    Returns the full path if found, else None.\n    \"\"\"\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            name, ext = os.path.splitext(file)\n            if name == video_name and ext.lower() in exts:\n                return os.path.join(root, file)\n    return None\n\ndef extract_category_from_key(video_key):\n    \"\"\"\n    Extract the category name from the start of the video key.\n    For example, 'Abuse001_x264' -> 'Abuse'\n    Adjust this logic if your naming convention is different.\n    \"\"\"\n    match = re.match(r'([A-Za-z]+)', video_key)\n    if match:\n        return match.group(1)\n    return \"Unknown\"\n\n# Create the output directory if it doesn't exist\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Load the JSON annotations\nwith open(ANNOTATIONS_FILE, 'r') as f:\n    annotations = json.load(f)\n\n# List to collect dictionaries with image paths and captions\ndata_entries = []\n\n# Iterate over each video entry in the JSON\nfor video_name, data in annotations.items():\n    # Identify the category from the video key\n    category = extract_category_from_key(video_name)\n\n    # Attempt to find the actual video file in subfolders\n    video_file = find_video_file(video_name, VIDEOS_DIR, VIDEO_EXTENSIONS)\n    if not video_file:\n        print(f\"[WARNING] Could not find file for video key '{video_name}'\")\n        continue\n\n    # Try to open the video\n    cap = cv2.VideoCapture(video_file)\n    if not cap.isOpened():\n        print(f\"[ERROR] Unable to open video file: {video_file}\")\n        continue\n\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    print(f\"Processing '{video_name}' in category '{category}' at {fps} fps.\")\n\n    # Get timestamps and sentences lists\n    timestamps = data.get(\"timestamps\", [])\n    sentences = data.get(\"sentences\", [])\n\n    frame_index = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break  # End of video\n\n        # Sample every 20th frame (modify this value as needed)\n        if frame_index % 20 == 0:\n            current_time = frame_index / fps\n            caption = None\n\n            # Determine which timestamp interval covers the current frame time\n            for idx, interval in enumerate(timestamps):\n                start, end = interval\n                if start <= current_time <= end:\n                    caption = sentences[idx]\n                    break\n\n            # If a caption is found, save the frame and record the data\n            if caption is not None:\n                image_filename = f\"{video_name}_frame{frame_index}.jpg\"\n                image_path = os.path.join(OUTPUT_DIR, image_filename)\n                cv2.imwrite(image_path, frame)\n\n                data_entries.append({\n                    'image_path': image_path,\n                    'caption': caption,\n                    'video_key': video_name,\n                    'category': category,\n                    'frame_index': frame_index\n                })\n                #print(f\"Saved: {image_path}, Caption: {caption}\")\n\n        frame_index += 1\n\n    cap.release()\n\n# Convert the collected data into a DataFrame and save as a CSV file\ndf = pd.DataFrame(data_entries)\ndf.to_csv(CSV_FILE, index=False)\nprint(f\"Data saved to {CSV_FILE}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T20:54:38.006398Z","iopub.execute_input":"2025-03-22T20:54:38.006763Z","execution_failed":"2025-03-22T21:39:55.275Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save output Data in a zip file","metadata":{}},{"cell_type":"code","source":"import shutil\n\n# Define the output directory\noutput_dir = \"/kaggle/working/test_output_frames\"\n\n# Define the name of the zip file\nzip_filename = \"test_ucf_output.zip\"\n\n# Create a zip file of the output directory\nshutil.make_archive(base_name= zip_filename.replace('.zip', ''), format='zip', root_dir=output_dir)\n\nprint(f\"Zipped the output directory to {zip_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T20:24:27.00678Z","iopub.execute_input":"2025-03-24T20:24:27.007355Z","iopub.status.idle":"2025-03-24T20:24:28.38601Z","shell.execute_reply.started":"2025-03-24T20:24:27.007269Z","shell.execute_reply":"2025-03-24T20:24:28.385018Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Get Download Link for the zip file to download it in Google Drive","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'train_ucf_output.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:33:12.71729Z","iopub.execute_input":"2025-03-24T18:33:12.717574Z","iopub.status.idle":"2025-03-24T18:33:12.725104Z","shell.execute_reply.started":"2025-03-24T18:33:12.71755Z","shell.execute_reply":"2025-03-24T18:33:12.724175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'test_ucf_output.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T20:24:28.388145Z","iopub.execute_input":"2025-03-24T20:24:28.388468Z","iopub.status.idle":"2025-03-24T20:24:28.397562Z","shell.execute_reply.started":"2025-03-24T20:24:28.388439Z","shell.execute_reply":"2025-03-24T20:24:28.396438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'Val_ucf_output.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T16:46:14.071098Z","iopub.execute_input":"2025-03-24T16:46:14.0714Z","iopub.status.idle":"2025-03-24T16:46:14.079374Z","shell.execute_reply.started":"2025-03-24T16:46:14.071375Z","shell.execute_reply":"2025-03-24T16:46:14.078408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport shutil\nfrom collections import defaultdict\n\n# === Paths ===\nVIDEO_DIR = \"/kaggle/input/ucaucf-crime-annotation-dataset/UCF_Crimes/UCF_Crimes/Videos\"\nANNOTATION_JSON_PATH = \"/kaggle/input/ucaucf-crime-annotation-dataset/UCFCrime_Train.json\"  # Adjust if different\nOUTPUT_DIR = \"/kaggle/working/sampled_ucf_videos\"\nOUTPUT_JSON_PATH = os.path.join(OUTPUT_DIR, \"sampled_annotations.json\")\n\n# === Load Annotations ===\nwith open(ANNOTATION_JSON_PATH, \"r\") as f:\n    annotations = json.load(f)\n\n# === Organize Videos by Category ===\ncategory_videos = defaultdict(list)\n\nfor video_name in annotations:\n    # Video name example: Abuse001_x264\n    for category in os.listdir(VIDEO_DIR):\n        if video_name.startswith(category):\n            category_videos[category].append(video_name)\n            break\n\n# === Sample Videos and Copy to Output ===\nsampled_data = {}\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nfor category, videos in category_videos.items():\n    sampled = random.sample(videos, min(3, len(videos)))\n    category_output_dir = os.path.join(OUTPUT_DIR, category)\n    os.makedirs(category_output_dir, exist_ok=True)\n\n    for video_name in sampled:\n        video_file = video_name + \".mp4\"  # Change if videos are .avi or another extension\n        src_video_path = os.path.join(VIDEO_DIR, category, video_file)\n        dst_video_path = os.path.join(category_output_dir, video_file)\n\n        if os.path.exists(src_video_path):\n            shutil.copy2(src_video_path, dst_video_path)\n            sampled_data[video_name] = annotations[video_name]\n        else:\n            print(f\"Warning: Video file not found: {src_video_path}\")\n\n# === Save Sampled Annotations ===\nwith open(OUTPUT_JSON_PATH, \"w\") as out_json:\n    json.dump(sampled_data, out_json, indent=4)\n1\nprint(f\"✅ Sampling complete! Videos saved in: {OUTPUT_DIR}\")\nprint(f\"✅ New JSON annotations file: {OUTPUT_JSON_PATH}\") \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:54:44.826365Z","iopub.execute_input":"2025-04-05T10:54:44.826775Z","iopub.status.idle":"2025-04-05T10:55:44.314266Z","shell.execute_reply.started":"2025-04-05T10:54:44.826739Z","shell.execute_reply":"2025-04-05T10:55:44.313149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Define the output directory\noutput_dir = \"/kaggle/working/sampled_ucf_videos\"\n\n# Define the name of the zip file\nzip_filename = \"sampled_ucf_videos.zip\"\n\n# Create a zip file of the output directory\nshutil.make_archive(base_name= zip_filename.replace('.zip', ''), format='zip', root_dir=output_dir)\n\nprint(f\"Zipped the output directory to {zip_filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T10:58:53.003565Z","iopub.execute_input":"2025-04-05T10:58:53.004006Z","iopub.status.idle":"2025-04-05T11:00:30.254545Z","shell.execute_reply.started":"2025-04-05T10:58:53.003971Z","shell.execute_reply":"2025-04-05T11:00:30.253109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'sampled_ucf_videos.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T11:00:30.266826Z","iopub.execute_input":"2025-04-05T11:00:30.267154Z","iopub.status.idle":"2025-04-05T11:00:30.286819Z","shell.execute_reply.started":"2025-04-05T11:00:30.267122Z","shell.execute_reply":"2025-04-05T11:00:30.285529Z"}},"outputs":[],"execution_count":null}]}